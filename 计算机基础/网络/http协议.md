### HTTP 历史

1. HTTP/0.9

20 世纪 90 年代初期的互联网世界非常简陋，计算机处理能力低，存储容量小，网速很慢，还是一片信息荒漠。网络上绝大多数的资源都是纯文本，很多通信协议也都使用纯文本，所以 HTTP 的设计也不可避免地受到了时代的限制

这一时期的 HTTP 被定义为 0.9 版，结构比较简单，为了便于服务器和客户端处理，它也采用了纯文本格式。蒂姆·伯纳斯 - 李最初设想的系统里的文档都是只读的，所以只允许用`GET`动作从服务器上获取 HTML 文档，并且在响应请求之后立即关闭连接，功能非常有限

2. HTTP/1.0

HTTP/1.0 版本在 1996 年正式发布。它在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大了，例如:
- 增加了 HEAD、POST 等新方法
- 增加了响应状态码，标记可能的错误原因
- 引入了协议版本号概念
- 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活
- 传输的数据不再仅限于文本

但 HTTP/1.0 并不是一个标准，只是记录已有实践和模式的一份参考文档，不具有实际的约束力，相当于一个备忘录

3. HTTP/1.1

从版本号我们就可以看到，HTTP/1.1 是对 HTTP/1.0 的小幅度修正。但一个重要的区别是：它是一个正式的标准，而不是一份可有可无的参考文档。这意味着今后互联网上所有的浏览器、服务器、网关、代理等等，只要用到 HTTP 协议，就必须严格遵守这个标准，相当于是互联网世界的一个立法

HTTP/1.1 主要的变更点有:
- 增加了 PUT、DELETE 等新的方法
- 增加了缓存管理和控制
- 明确了连接管理，允许持久连接
- 允许响应数据分块（chunked），利于传输大文件
- 强制要求 Host 头，让互联网主机托管成为可能

HTTP/1.1 的推出可谓是众望所归，开启了后续的Web 1.0, Web 2.0时代

4. HTTP/2.0

HTTP/1.1 发布之后，整个互联网世界呈现出了爆发式的增长, 这期间也出现了一些对 HTTP 不满的意见，主要就是连接慢，无法跟上迅猛发展的互联网，但 HTTP/1.1 标准一直岿然不动，无奈之下人们只好发明各式各样的小花招来缓解这些问题，比如以前常见的切图、JS 合并等网页优化手段

Google 把 SPDY 推上了标准的宝座，互联网标准化组织以 SPDY 为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2，RFC 编号 7540

HTTP/2 的制定充分考虑了现今互联网的现状：宽带、移动、不安全，在高度兼容 HTTP/1.1 的同时在性能改善方面做了很大努力，主要的特点有:
- 二进制协议，不再是纯文本
- 可发起多个请求，废弃了 1.1 里的管道
- 使用专用算法压缩头部，减少数据传输量
- 允许服务器主动向客户端推送数据
- 增强了安全性，事实上要求加密通信

虽然 HTTP/2 到今天已经四年了，也衍生出了 gRPC 等新协议，但由于 HTTP/1.1 实在是太过经典和强势，目前它的普及率还比较低，大多数网站使用的仍然还是 20 年前的 HTTP/1.1

5. HTTP/3

在 HTTP/2 还处于草案之时，Google 又发明了一个新的协议，叫做 QUIC，而且还是相同的套路，继续在 Chrome 和自家服务器里试验着玩，依托它的庞大用户量和数据量，持续地推动 QUIC 协议成为互联网上的既成事实

2018 年，互联网标准化组织 IETF 提议将`HTTP over QUIC`更名为`HTTP/3`并获得批准，HTTP/3 正式进入了标准化制订阶段，也许两三年后就会正式发布，到时候我们很可能会跳过 HTTP/2 直接进入 HTTP/3

### HTTP是什么

HTTP 就是超文本传输协议，也就是 HyperText Transfer Protocol

超文本传输协议:
- 超文本
- 传输
- 协议

HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式

计算机和网络世界里有数不清的各种角色：CPU、内存、总线、磁盘、操作系统、浏览器、网关、服务器……这些角色之间相互通信也必然会有各式各样、五花八门的协议，用处也各不相同，例如广播协议、寻址协议、路由协议、隧道协议、选举协议等等

HTTP 是一个传输协议，所谓的传输（Transfer）其实很好理解，就是把一堆东西从 A 点搬到 B 点，或者从 B 点搬到 A 点

HTTP 协议是一个双向协议，也就是说，有两个最基本的参与者 A 和 B，从 A 开始到 B 结束，数据在 A 和 B 之间双向而不是单向流动。通常我们把先发起传输动作的 A 叫做请求方，把后接到传输的 B 叫做应答方或者响应方

数据虽然是在 A 和 B 之间传输，但并没有限制只有 A 和 B 这两个角色，允许中间有中转或者接力，这样，传输方式就从`A<===>B`，变成了`A<=>X<=>Y<=>Z<=>B`，A 到 B 的传输过程中可以存在任意多个“中间人”，而这些中间人也都遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意的额外功能，例如安全认证、数据压缩、编码转换等等，优化整个传输过程

即**HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范**

所谓文本（Text），就表示 HTTP 传输的不是 TCP/UDP 这些底层协议里被切分的杂乱无章的二进制包，而是完整的、有意义的数据，可以被浏览器、服务器这样的上层应用程序处理

在互联网早期，文本只是简单的字符文字，但发展到现在，文本的涵义已经被大大地扩展了，图片、音频、视频、甚至是压缩包，在 HTTP 眼里都可以算做是文本

所谓超文本，就是超越了普通文本的文本，它是文字、图片、音频和视频等的混合体，最关键的是含有超链接，能够从一个超文本跳跃到另一个超文本，形成复杂的非线性、网状的结构关系

对于超文本，我们最熟悉的就应该是 HTML 了，它本身只是纯文字文件，但内部用很多标签定义了对图片、音频、视频等的链接，再经过浏览器的解释，呈现在我们面前的就是一个含有多种视听信息的页面

**在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位**


### HTTP相关的各种概念

互联网的正式名称是 Internet，里面存储着无穷无尽的信息资源，我们通常所说的上网实际上访问的只是互联网的一个子集万维网（World Wide Web），它基于 HTTP 协议，传输 HTML 等超文本资源，能力也就被限制在 HTTP 协议之内。互联网上还有许多万维网之外的资源，例如常用的电子邮件、BT 和 Magnet 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。不过由于 HTTP 协议非常灵活、易于扩展，而且超文本的表述能力很强，所以很多其他原本不属于 HTTP 的资源也可以“包装”成 HTTP 来访问，这就是我们为什么能够总看到各种“网页应用”——例如微信网页版,邮箱网页版的原因

#### 1.浏览器

上网就要用到浏览器，常见的浏览器有 Google 的 Chrome、Mozilla 的 Firefox、Apple 的 Safari、Microsoft 的 IE 和 Edge

浏览器本质上是一个 HTTP 协议中的请求方，使用 HTTP 协议获取网络上的各种资源。当然，为了让我们更好地检索查看网页，它还集成了很多额外的功能

在 HTTP 协议里，浏览器的角色被称为`User Agent`即用户代理，意思是作为访问者的代理来发起 HTTP 请求。不过在不引起混淆的情况下，我们通常都简单地称之为`客户端`

#### 2.Web 服务器

Web 服务器是一个很大也很重要的概念，它是 HTTP 协议里响应请求的主体，通常也把控着绝大多数的网络资源，在网络世界里处于强势地位

Nginx 是 Web 服务器里的后起之秀，特点是高性能、高稳定，且易于扩展。在高流量的网站里更是不二之选

#### 3.CDN

浏览器和服务器是 HTTP 协议的两个端点, 浏览器通常不会直接连到服务器，中间会经过重重关卡，其中的一个重要角色就叫做 CDN

CDN，全称是`Content Delivery Network`，翻译过来就是内容分发网络。它应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求

它可以缓存源站的数据，让浏览器的请求不用千里迢迢地到达源站服务器，直接在半路就可以获取响应。如果 CDN 的调度算法很优秀，更可以找到离用户最近的节点，大幅度缩短响应时间

CDN 也是现在互联网中的一项重要基础设施，除了基本的网络加速外，还提供负载均衡、安全防护、边缘计算、跨运营商网络等功能，能够成倍地放大源站服务器的服务能力，很多云服务商都把 CDN 作为产品的一部分

#### 4.爬虫

但 HTTP 协议并没有规定用户代理后面必须是真正的人类，它也完全可以是机器人，这些机器人的正式名称就叫做爬虫（Crawler），实际上是一种可以自动访问 Web 资源的应用程序

爬虫也有不好的一面，它会过度消耗网络资源，占用服务器和带宽，影响网站对真实数据的分析，甚至导致敏感信息泄漏。所以，又出现了反爬虫技术，通过各种手段来限制爬虫。其中一项就是君子协定`robots.txt`，约定哪些该爬，哪些不该爬

无论是爬虫还是反爬虫，用到的基本技术都是两个，一个是 HTTP，另一个就是 HTML

#### 5.HTML

HTML 是 HTTP 协议传输的主要内容之一，它描述了超文本页面，用各种标签定义文字、图片等资源和排版布局，最终由浏览器渲染出可视化页面

#### 6.WAF

WAF 意思是网络应用防火墙。与硬件防火墙类似，它是应用层面的防火墙，专门检测 HTTP 流量，是防护 Web 应用的安全技术。WAF 通常位于 Web 服务器之前，可以阻止如 SQL 注入、跨站脚本等攻击，目前应用较多的一个开源项目是 ModSecurity，它能够完全集成进 Apache 或 Nginx

### 与HTTP相关的各种协议

#### 1.TCP/IP

TCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈

这个协议栈有四层，最上层是应用层，最下层是链接层，TCP 和 IP 则在中间：TCP 属于传输层，IP 属于网际层。协议的层级关系模型非常重要

- IP 协议是`Internet Protocol`的缩写，主要目的**是解决寻址和路由问题**，以及如何在两点间传送数据包。IP 协议使用“IP 地址”的概念来定位互联网上的每一台计算机
- TCP 协议是`Transmission Control Protocol`的缩写，意思是传输控制协议，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础

现在我们使用的 IP 协议大多数是 v4 版，地址是四个用`.`分隔的数字，例如`192.168.0.1`，总共有 `2^32`，大约 42 亿个可以分配的地址。看上去好像很多，但互联网的快速发展让地址的分配管理很快就捉襟见肘。所以，就又出现了 v6 版，使用 8 组`:`分隔的数字作为地址，容量扩大了很多，有 `2^128` 个，在未来的几十年里应该是足够用了

可靠是指保证数据不丢失，字节流是指保证数据完整，所以在 TCP 协议的两端可以如同操作文件一样访问传输的数据，就像是读写在一个密闭的管道里“流动”的字节

**HTTP 是一个传输协议，但它不关心寻址、路由、数据完整性等传输细节，而要求这些工作都由下层来处理。因为互联网上最流行的是 TCP/IP 协议，而它刚好满足 HTTP 的要求，所以互联网上的 HTTP 协议就运行在了 TCP/IP 上，HTTP 也就可以更准确地称为`HTTP over TCP/IP`**


#### 2.DNS

域名系统（Domain Name System）用有意义的名字来作为 IP 地址的等价替代

在 DNS 中，域名（Domain Name）又称为主机名（Host），为了更好地标记不同国家或组织的主机，让名字更好记，所以被设计成了一个有层次的结构

域名用`.`分隔成多个单词，级别从左到右逐级升高，最右边的被称为顶级域名。对于顶级域名，可能你随口就能说出几个，例如表示商业公司的`com`、表示教育机构的`edu`

但想要使用 TCP/IP 协议来通信仍然要使用 IP 地址，所以需要把域名做一个转换，映射到它的真实 IP，这就是所谓的**域名解析**

#### 3.URI/URL

DNS 和 IP 地址只是标记了互联网上的主机，但主机上有那么多文本、图片、页面，到底要找哪一个呢？

`URI`（Uniform Resource Identifier），中文名称是 **统一资源标识符**，使用它就能够唯一地标记互联网上资源

`URI` 另一个更常用的表现形式是 URL（Uniform Resource Locator）， **统一资源定位符**，也就是我们俗称的网址，它实际上是 URI 的一个子集，不过因为这两者几乎是相同的，差异不大，所以通常不会做严格的区分

URI 主要有三个基本的部分构成:
- 协议名：即访问该资源应当使用的协议，在这里是`http`
- 主机名：即互联网上主机的标记，可以是域名或 IP 地址，在这里是`nginx.org`
- 路径：即资源在主机上的位置，使用`/`分隔多级目录，在这里是`/en/download.html`


#### 4.HTTPS

HTTPS 它的全称是`HTTP over SSL/TLS`，也就是运行在 SSL/TLS 协议上的 HTTP, 这里是 SSL/TLS，而不是 TCP/IP，它是一个负责加密通信的安全协议，建立在 TCP/IP 之上，所以也是个可靠的传输协议，可以被用作 HTTP 的下层

HTTPS 相当于`HTTP+SSL/TLS+TCP/IP`

SSL 使用了许多密码学最先进的研究成果，综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道，为 HTTP 套上一副坚固的盔甲


#### 5.代理

代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为中转站，既可以转发客户端的请求，也可以转发服务器的应答

- 匿名代理：完全隐匿了被代理的机器，外界看到的只是代理服务器
- 透明代理：顾名思义，它在传输过程中是透明开放的，外界既知道代理，也知道客户端
- 正向代理：靠近客户端，代表客户端向服务器发送请求
- 反向代理：靠近服务器端，代表服务器响应客户端的请求

CDN实际上就是一种代理，它代替源站服务器响应客户端的请求，通常扮演着透明代理和反向代理的角色

由于代理在传输过程中插入了一个中间层，所以可以在这个环节做很多有意思的事情，比如：
- 负载均衡：把访问请求均匀分散到多台机器，实现访问集群化
- 内容缓存：暂存上下行的数据，减轻后端的压力
- 安全防护：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器
- 数据处理：提供压缩、加密等额外的功能


### 常说的`四层`和`七层`到底是什么

- 四层负载均衡
- 七层负载均衡
- 二层转发
- 三层路由

#### TCP/IP 网络分层模型

TCP/IP 协议总共有四层，每一层需要下层的支撑，同时又支撑着上层

- 第一层叫链接层（link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层
- 第二层叫网际层（internet layer），IP 协议就处在这一层。因为 IP 协议定义了`IP 地址`的概念，所以就可以在`链接层`的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再翻译成 MAC 地址就可以了
- 第三层叫传输层（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间可靠地传输，是 TCP 协议工作的层次，另外还有它的一个小伙伴UDP
- 协议栈的第四层叫应用层（application layer），由于下面的三层把基础打得非常好，所以在这一层就百花齐放了，有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有我们的 HTTP


TCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的字节流，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收

关于 TCP 和 UDP 可以展开讨论的话题还有很多:
- 三次握手
- 四次挥手

**MAC 层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包**


#### OSI 网络分层模型

OSI 模型分成了七层，部分层次与 TCP/IP 很像，从下到上分别是：
- 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等
- 第二层：数据链路层，它基本相当于 TCP/IP 的链接层
- 第三层：网络层，相当于 TCP/IP 里的网际层
- 第四层：传输层，相当于 TCP/IP 里的传输层
- 第五层：会话层，维护网络中的连接状态，即保持会话和同步
- 第六层：表示层，把数据转换为合适、可理解的语法和语义
- 第七层：应用层，面向具体的应用传输数据

在 OSI 模型之后，四层, 七层 这样的说法就逐渐流行开了

**所谓的`四层负载均衡`就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡**

**所谓的`七层负载均衡`就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器**

**二层转发：设备工作在链路层，帧在经过交换机设备时，检查帧的头部信息，拿到目标mac地址，进行本地转发和广播**

**三层路由：设备工作在ip层，报文经过有路由功能的设备时，设备分析报文中的头部信息，拿到ip地址，根据网段范围，进行本地转发或选择下一个网关**

#### TCP/IP 协议栈的工作方式

1. 假设你想把一件毛绒玩具送给朋友，但你要先拿个塑料袋套一下，这件玩具就相当于 HTTP 协议里要传输的内容，比如 HTML，然后 HTTP 协议为它加一个 HTTP 专用附加数据
2. 你把玩具交给快递小哥，为了保护货物，他又加了层包装再贴了个标签，相当于在 TCP 层给数据再次打包，加上了 TCP 头
3. 接着快递小哥下楼，把包裹放进了三轮车里，运到集散点，然后再装进更大的卡车里，相当于在 IP 层、MAC 层对 TCP 数据包加上了 IP 头、MAC 头
4. 之后经过漫长的运输，包裹到达目的地，要卸货再放进另一位快递员的三轮车，就是在 IP 层、MAC 层传输后拆包
5. 快递员到了你朋友的家门口，撕掉标签，去除了 TCP 层的头，你朋友再拆掉塑料袋包装，也就是 HTTP 头，最后就拿到了玩具，也就是真正的 HTML 页面

**HTTP 协议的传输过程就是这样通过协议栈逐层向下，每一层都添加本层的专有数据，层层打包，然后通过下层发送出去, 接收数据则是相反的操作，从下往上穿过协议栈，逐层拆包，每层去掉本层的专有头，上层就会拿到自己的数据**

但下层的传输过程对于上层是完全透明的，上层也不需要关心下层的具体实现细节，所以就 HTTP 层次来看，它不管下层是不是 TCP/IP 协议，看到的只是一个可靠的传输链路，只要把数据加上自己的头，对方就能原样收到

### 域名那些事

在 IP 地址之上再来一次抽象，把数字形式的 IP 地址转换成更有意义更好记的名字，在字符串的层面上再增加新玩法。于是，`DNS 域名系统`就这么出现了

#### 域名的形式

域名是一个有层次的结构，是一串用`.`分隔的多个单词，最右边的被称为`顶级域名`，然后是`二级域名`，层级关系向左依次降低

最左边的是主机名，通常用来表明主机的用途，比如`www`表示提供万维网服务、`mail`表示提供邮件服务

看一下这个的域名`time.ifcalm.org`，这里的`org`就是顶级域名，`ifcalm`是二级域名，`time`则是主机名。使用这个域名，DNS 就会把它转换成相应的 IP 地址，你就可以访问网站了

**域名不仅能够代替 IP 地址，还有许多其他的用途**

在 Apache、Nginx 这样的 Web 服务器里，域名可以用来标识虚拟主机，决定由哪个虚拟主机来对外提供服务

域名本质上还是个名字空间系统，使用多级域名就可以划分出不同的国家、地区、组织、公司、部门，每个域名都是独一无二的，可以作为一种身份的标识

因为这个特性，域名也被扩展到了其他应用领域，比如 Java 的包机制就采用域名作为命名空间，只是它使用了反序

#### 域名的解析

就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是**域名解析**

DNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：
1. 根域名服务器（Root DNS Server）：管理顶级域名服务器，返回`com`, `net`, `cn`等顶级域名服务器的 IP 地址
2. 顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址
3. 权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址


在这里**根域名服务器**是关键，它必须是众所周知的，否则下面的各级服务器就无从谈起了。目前全世界共有 13 组根域名服务器，又有数百台的镜像，保证一定能够被访问到

有了这个系统以后，任何一个域名都可以在这个树形结构里从顶至下进行查询，就好像是把域名从右到左顺序走了一遍，最终就获得了域名对应的 IP 地址

例如，你要访问`www.apple.com`，就要进行下面的三次查询：
1. 访问根域名服务器，它会告诉你`com`顶级域名服务器的地址
2. 访问`com`顶级域名服务器，它再告诉你`apple.com`域名服务器的地址
3. 最后访问`apple.com`域名服务器，就得到了`www.apple.com`的地址

虽然核心的 DNS 系统遍布全球，服务能力很强也很稳定，但如果全世界的网民都往这个系统里挤，即使不挤瘫痪了，访问速度也会很慢。所以在核心 DNS 系统之外，还有两种手段用来减轻域名解析的压力，并且能够更快地获取结果，基本思路就是**缓存**

首先，许多大公司、网络运行商都会建立自己的 DNS 服务器，作为用户 DNS 查询的代理，代替用户访问核心 DNS 系统。这些服务器被称为`非权威域名服务器`，可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址

这些 DNS 服务器的数量要比核心系统的服务器多很多，而且大多部署在离用户很近的地方。比较知名的 DNS 有 Google 的`8.8.8.8`，Microsoft 的`4.2.2.1`，还有 CloudFlare 的`1.1.1.1`等等

其次，操作系统里也会对 DNS 解析结果做缓存，如果你之前访问过`www.apple.com`，那么下一次在浏览器里再输入这个网址的时候就不会再跑到 DNS 那里去问了，直接在操作系统里就可以拿到 IP 地址

另外，操作系统里还有一个特殊的主机映射文件，通常是一个可编辑的文本，在 Linux 里是`/etc/hosts`，在 Windows 里是`C:\WINDOWS\system32\drivers\etc\hosts`，如果操作系统在缓存里找不到 DNS 记录，就会找这个文件

有了上面的DNS 服务器、操作系统缓存和 hosts 文件后，很多域名解析的工作就都不用跋山涉水了，直接在本地或本机就能解决，不仅方便了用户，也减轻了各级 DNS 服务器的压力，效率就大大提升了

#### 域名新玩法

第一种，也是最简单的，**重定向**。因为域名代替了 IP 地址，所以可以让对外服务的域名不变，而主机的 IP 地址任意变动。当主机有情况需要下线、迁移时，可以更改 DNS 记录，让域名指向其他的机器

第二种，因为域名是一个名字空间，所以可以使用 bind9 等开源软件搭建一个在内部使用的 DNS，作为名字服务器。这样我们开发的各种内部服务就都用域名来标记，比如数据库服务都用域名`mysql.inner.app`，商品服务都用`goods.inner.app`，发起网络通信时也就不必再使用写死的 IP 地址了，可以直接用域名

第三种玩法包含了前两种，也就是基于域名实现的负载均衡:
- 第一种方式，因为域名解析可以返回多个 IP 地址，所以一个域名可以对应多台主机，客户端收到多个 IP 地址后，就可以自己使用轮询算法依次向服务器发起请求，实现负载均衡
- 第二种方式，域名解析可以配置内部的策略，返回离客户端最近的主机，或者返回当前服务质量最好的主机，这样在 DNS 端把请求分发到不同的服务器，实现负载均衡


1. 域名屏蔽，对域名直接不解析，返回错误，让你无法拿到 IP 地址，也就无法访问网站
2. 域名劫持，也叫域名污染，你要访问 A 网站，但 DNS 给了你 B 网站


### 键入网址再按下回车，后面究竟发生了什么

HTTP 协议是运行在 TCP/IP 基础上的，依靠 TCP/IP 协议来实现数据的可靠传输。所以浏览器要用 HTTP 协议收发数据，首先要做的就是建立 TCP 连接

浏览器要依照 TCP 协议的规范，使用**三次握手**建立与 Web 服务器的连接

经过 SYN、SYN/ACK、ACK 的三个包之后，浏览器与服务器的 TCP 连接就建立起来了

有了可靠的 TCP 连接通道后，HTTP 协议就可以开始工作了

#### 浏览器 HTTP 请求过程

1. 浏览器从地址栏的输入中获得服务器的 IP 地址和端口号
2. 浏览器用 TCP 的三次握手与服务器建立连接
3. 浏览器向服务器发送拼好的报文
4. 服务器收到报文后处理请求，同样拼好报文再发给浏览器
5. 浏览器解析报文，渲染输出页面

#### 使用域名访问 Web 服务器

浏览器看到了网址里的`www.ifcalm.net`，发现它不是数字形式的 IP 地址，那就肯定是域名了，于是就会发起域名解析动作，通过访问一系列的域名解析服务器，试图把这个域名翻译成 TCP/IP 协议里的 IP 地址

在域名解析的过程中会有多级的缓存，浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 hosts

#### 真实的网络世界

接入网络的同时，网络运行商会给你的设备分配一个 IP 地址，这个地址可能是静态分配的，也可能是动态分配的。静态 IP 就始终不变，而动态 IP 可能你下次上网就变了

假设你要访问的是 Apple 网站，显然你是不知道它的真实 IP 地址的，在浏览器里只能使用域名`www.apple.com`访问，那么接下来要做的必然是域名解析。这就要用 DNS 协议开始从操作系统、本地 DNS、根 DNS、顶级 DNS、权威 DNS 的层层解析，当然这中间有缓存，可能不会费太多时间就能拿到结果

互联网上还有另外一个重要的角色 CDN，DNS 解析可能会给出 CDN 服务器的 IP 地址，这样你拿到的就会是 CDN 服务器而不是目标网站的实际地址

因为 CDN 会缓存网站的大部分资源，比如图片、CSS 样式表，所以有的 HTTP 请求就不需要再发到 Apple，CDN 就可以直接响应你的请求，把数据发给你

由 PHP、Java 等后台服务动态生成的页面属于动态资源，CDN 无法缓存，只能从目标网站获取。于是你发出的 HTTP 请求就要开始在互联网上的“漫长跋涉”，经过无数的路由器、网关、代理，最后到达目的地

目标网站的服务器对外表现的是一个 IP 地址，但为了能够扛住高并发，在内部也是一套复杂的架构。通常在入口是负载均衡设备，例如四层的 LVS 或者七层的 Nginx，在后面是许多的服务器，构成一个更强更稳定的集群

负载均衡设备会先访问系统里的缓存服务器，通常有 memory 级缓存 Redis 和 disk 级缓存 Varnish，它们的作用与 CDN 类似，不过是工作在内部网络里，把最频繁访问的数据缓存几秒钟或几分钟，减轻后端应用服务器的压力

如果缓存服务器里也没有，那么负载均衡设备就要把请求转发给应用服务器了。这里就是各种开发框架大显神通的地方了，例如 Java 的 Tomcat/Netty/Jetty，Python 的 Django，还有 PHP、Node.js、Golang 等等。它们又会再访问后面的 MySQL、PostgreSQL、MongoDB 等数据库服务，实现用户登录、商品查询、购物下单、扣款支付等业务操作，然后把执行的结果返回给负载均衡设备，同时也可能给缓存服务器里也放一份

应用服务器的输出到了负载均衡设备这里，请求的处理就算是完成了，就要按照原路再走回去，还是要经过许多的路由器、网关、代理。如果这个资源允许缓存，那么经过 CDN 的时候它也会做缓存，这样下次同样的请求就不会到达源站了

最后网站的响应数据回到了你的设备，它可能是 HTML、JSON、图片或者其他格式的数据，需要由浏览器解析处理才能显示出来，如果数据里面还有超链接，指向别的资源，那么就又要重走一遍整个流程，直到所有的资源都下载完


### HTTP报文

HTTP 协议的核心部分是: 它传输的报文内容

HTTP 协议与 TCP/UDP 类似，同样也需要在实际传输的数据前附加一些头数据，不过与 TCP/UDP 不同的是，它是一个纯文本的协议，所以头数据都是 `ASCII` 码的文本，可以很容易地用肉眼阅读，不用借助程序解析也能够看懂

HTTP 协议的请求报文和响应报文的结构基本相同，由三大部分组成:

- 起始行（start line）：描述请求或响应的基本信息
- 头部字段集合（header）：使用 key-value 形式更详细地说明报文
- 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据

其中前两部分起始行和头部字段经常又合称为`请求头`或`响应头`，消息正文又称为实体，但与`header`对应，很多时候就直接称为`body`

HTTP 协议规定报文必须有 `header`，但可以没有 `body`，而且在 `header` 之后必须要有一个空行，也就是`CRLF`，十六进制的`0D0A`

#### 请求行

它简要地描述了客户端想要如何操作服务器端的资源

请求行由三部分构成：
- 请求方法：是一个动词，如 GET/POST，表示对资源的操作
- 请求目标：通常是一个 URI，标记了请求方法要操作的资源
- 版本号：表示报文使用的 HTTP 协议版本

这三个部分通常使用空格来分隔，最后要用 CRLF 换行表示结束

#### 状态行

响应报文里的起始行，在这里它不叫响应行，而是叫状态行，意思是服务器响应的状态

比起请求行来说，状态行要简单一些，同样也是由三部分构成：
- 版本号：表示报文使用的 HTTP 协议版本
- 状态码：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误
- 原因：作为数字状态码补充，是更详细的解释文字，帮助人理解原因

#### 头部字段

请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头

头部字段是 key-value 的形式，key 和 value 之间用`:`分隔，最后用 CRLF 换行表示字段结束

HTTP 头字段非常灵活，不仅可以使用标准里的 Host、Connection 等已有头，也可以任意添加自定义头，这就给 HTTP 协议带来了无限的扩展可能

**使用头字段需要注意下面几点：**
- 字段名不区分大小写，例如`Host`也可以写成`host`，但首字母大写的可读性更好
- 字段名里不允许出现空格，可以使用连字符`-`，但不能使用下划线`_`。例如，`test-name`是合法的字段名，而`test name`, `test_name`是不正确的字段名
- 字段名后面必须紧接着`:`，不能有空格，而`:`后的字段值前可以有多个空格
- 字段的顺序是没有意义的，可以任意排列不影响语义
- 字段原则上不能重复，除非这个字段本身的语义允许，例如 `Set-Cookie`

#### 常用头字段

- 通用字段：在请求头和响应头里都可以出现
- 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件
- 响应字段：仅能出现在响应头里，补充说明响应报文的信息
- 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息


1. Host 字段: 它属于请求字段，只能出现在请求头里，它同时也是唯一一个 `HTTP/1.1` 规范里要求必须出现的字段，也就是说，如果请求头里没有 `Host`，那这就是一个错误的报文, Host 字段告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用 Host 字段来选择
2. `User-Agent` 是请求字段，只出现在请求头里。它使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面
3. `Date` 字段是一个通用字段，但通常出现在响应头里，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略
4. `Server` 字段是响应字段，只能出现在响应头里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号. Server 字段也不是必须要出现的，因为这会把服务器的一部分信息暴露给外界，如果这个版本恰好存在 bug，那么黑客就有可能利用 bug 攻陷服务器。所以，有的网站响应头里要么没有这个字段，要么就给出一个完全无关的描述信息
5. 实体字段里要说的一个是 `Content-Length`，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输


----------------------------------------------

### 请求方法

它的实际含义就是客户端发出了一个动作指令，要求服务器端对 URI 定位的资源执行这个动作

目前 HTTP/1.1 规定了八种方法，单词都必须是大写的形式：
- GET：获取资源，可以理解为读取或者下载数据
- HEAD：获取资源的元信息
- POST：向资源提交数据，相当于写入或上传数据
- PUT：类似 POST
- DELETE：删除资源
- CONNECT：建立特殊的连接隧道
- OPTIONS：列出可对资源实行的方法
- TRACE：追踪请求 - 响应的传输路径

#### GET/HEAD

它的含义是请求从服务器获取资源，这个资源既可以是静态的文本、页面、图片、视频，也可以是由 PHP、Java 动态生成的页面或者其他格式的数据

`GET` 方法虽然基本动作比较简单，但搭配 URI 和其他头字段就能实现对资源更精细的操作, 例如，在 URI 后使用`#`，就可以在获取页面后直接定位到某个标签所在的位置；使用 `If-Modified-Since` 字段就变成了`有条件的请求`，仅当资源被修改时才会执行获取动作；使用 Range 字段就是`范围请求`，只获取资源的一部分数据

HEAD 方法与 GET 方法类似，也是请求从服务器获取资源，服务器的处理机制也是一样的，但服务器不会返回请求的实体数据，只会传回响应头，也就是资源的元信息, HEAD 方法可以看做是 GET 方法的一个简化版。因为它的响应头与 GET 完全相同，所以可以用在很多并不真正需要资源的场合，避免传输 body 数据的浪费. 比如，想要检查一个文件是否存在，只要发个 HEAD 请求就可以了，没有必要用 GET 把整个文件都取下来。再比如，要检查文件是否有最新版本，同样也应该用 HEAD，服务器会在响应头里把文件的修改时间传回来

#### POST/PUT

GET 和 HEAD 方法是从服务器获取数据，而 POST 和 PUT 方法则是相反操作，向 URI 指定的资源提交数据，数据就放在报文的 body 里

比如，你上论坛灌水，敲了一堆字后点击发帖按钮，浏览器就执行了一次 POST 请求，把你的文字放进报文的 body 里，然后拼好 POST 请求头，通过 TCP 协议发给服务器

在实际应用中，PUT 用到的比较少。而且，因为它与 POST 的语义、功能太过近似，有的服务器甚至就直接禁止使用 PUT 方法，只用 POST 方法上传数据


#### 其他方法

`DELETE` 方法指示服务器删除资源，因为这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记。当然，更多的时候服务器就直接不处理 `DELETE` 请求

`CONNECT` 是一个比较特殊的方法，要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色

`OPTIONS` 方法要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回。它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持

`TRACE` 方法多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用

#### 安全与幂等

在 HTTP 协议里，所谓的**安全**是指请求方法不会破坏服务器上的资源，即不会对服务器上的资源造成实质的修改

按照这个定义，只有 GET 和 HEAD 方法是安全的，因为它们是只读操作，只要服务器不故意曲解请求方法的处理方式，无论 GET 和 HEAD 操作多少次，服务器上的数据都是安全的

而 POST/PUT/DELETE 操作会修改服务器上的资源，增加或删除数据，所以是不安全的

所谓的**幂等**实际上是一个数学用语，被借用到了 HTTP 协议里，意思是多次执行相同的操作，结果也都是相同的，即多次`幂`后结果相等

GET 和 HEAD 既是安全的也是幂等的，DELETE 可以多次删除同一个资源，效果都是资源不存在，所以也是幂等的

POST 是新增或提交数据，多次提交数据会创建多个资源，所以不是幂等的；而 PUT 是替换或更新数据，多次更新一个资源，资源还是会第一次更新的状态，所以是幂等的

-----------------------------------------

### 正确的网址

#### 用什么来标记服务器上的资源呢？

用的是 URI，也就是统一资源标识符（Uniform Resource Identifier）。因为它经常出现在浏览器的地址栏里，简称网址

URI 不完全等同于网址，它包含有 `URL` 和 `URN` 两个部分，在 HTTP 世界里用的网址实际上是 URL——统一资源定位符（Uniform Resource Locator）。但因为 URL 实在是太普及了，所以常常把这两者简单地视为相等

#### URI 的格式

URI 本质上是一个字符串，这个字符串的作用是唯一地标记资源的位置或者名字

URI 最常用的形式，由 scheme、host:port、path 和 query 四个部分组成，但有的部分可以视情况省略

`scheme://` + `host:port` + `path` + `?query`

#### URI 的基本组成

URI 第一个组成部分叫 scheme，翻译成中文叫协议名，表示资源应该使用哪种协议来访问

最常见的当然就是http了，表示使用 HTTP 协议。另外还有https，表示使用经过加密、安全的 HTTPS 协议。此外还有其他不是很常见的 scheme，例如 ftp、ldap、file、news 等

```

http://nginx.org
http://www.chrono.com:8080/11-1
https://tools.ietf.org/html/rfc7230
file:///D:/http_study/www/
```

#### URI 的查询参数

使用`协议名 + 主机名 + 路径`的方式，已经可以精确定位网络上的任何资源了。但这还不够，很多时候我们还想在操作资源的时候附加一些额外的修饰参数

URI 后面还有一个query部分，它在 path 之后，用一个`?`开始，但不包含`?`，表示对资源附加的额外要求

查询参数 query 有一套自己的格式，是多个`key=value`的字符串，这些 KV 值用字符`&`连接，浏览器和服务器都可以按照这个格式把长串的查询参数解析成可理解的字典或关联数组形式

````
http://www.chrono.com:8080/11-1?uid=1234&name=mario&referer=xxx
````

#### URI 的完整格式

`scheme://`+`user:passwd@`+`host:post`+`path`+`?query`+`#fragment`

第一个多出的部分是协议名之后、主机名之前的身份信息`user:passwd@`，表示登录主机时的用户名和密码，但现在已经不推荐使用这种形式了，因为它把敏感信息以明文形式暴露出来，存在严重的安全隐患

第二个多出的部分是查询参数后的片段标识符`#fragment`，它是 URI 所定位的资源内部的一个锚点或者说是标签，浏览器可以在获取资源后直接跳转到它指示的位置. 但片段标识符仅能由浏览器这样的客户端使用，服务器是看不到的。也就是说，浏览器永远不会把带`#fragment`的 URI 发送给服务器，服务器也永远不会用这种方式去处理资源的片段

#### URI 的编码

在 URI 里只能使用 ASCII 码，但如果要在 URI 里使用英语以外的汉语等其他语言该怎么办呢, 还有某些特殊的 URI，会在 path、query 里出现`@&?`等起界定符作用的字符，会导致 URI 解析错误，这时又该怎么办呢

URI 引入了编码机制，对于 ASCII 码以外的字符集和特殊字符做一个特殊的操作，把它们转换成与 URI 语义不冲突的形式, 俗称转义

例如，空格被转义成`%20`，`?`被转义成`%3F`。而中文、日文等则通常使用 UTF-8 编码后再转义，例如银河会被转义成`%E9%93%B6%E6%B2%B3`

**把字符（unicode）编码成utf-8，utf-8是用1-4个字节表示的，所以每个字节转换成16进制并在前面用百分号（%）连接，最后并把每个字节转换的结果连接起来**

有了这个编码规则后，URI 就更加完美了，可以支持任意的字符集用任何语言来标记资源


### 响应状态码的使用

响应报文由响应头加响应体数据组成，响应头又由状态行和头字段构成

**状态码**: 它是一个十进制数字，以代码的形式表示服务器对请求的处理结果，就像我们通常编写程序时函数返回的错误码一样

目前 RFC 标准里总共有 41 个状态码，但状态码的定义是开放的，允许自行扩展。所以 Apache、Nginx 等 Web 服务器都定义了一些专有的状态码。如果你自己开发 Web 应用，也完全可以在不冲突的前提下定义新的代码

#### 状态码

RFC 标准把状态码分成了五类，用数字的第一位表示分类

- 1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作
- 2××：成功，报文已经收到并被正确处理
- 3××：重定向，资源位置发生变动，需要客户端重新发送请求
- 4××：客户端错误，请求报文有误，服务器无法处理
- 5××：服务器错误，服务器在处理请求时内部发生了错误

客户端作为请求的发起方，获取响应报文后，需要通过状态码知道请求是否被正确处理，是否要再次发送请求，如果出错了原因又是什么。这样才能进行下一步的动作，要么发送新请求，要么改正错误重发请求

服务器端作为请求的接收方，也应该很好地运用状态码。在处理请求时，选择最恰当的状态码回复客户端，告知客户端处理的结果，指示客户端下一步应该如何行动。特别是在出错的时候，尽量不要简单地返 400、500 这样意思含糊不清的状态码

#### 1××

1××类状态码属于提示信息，是协议处理的中间状态，实际能够用到的时候很少

我们偶尔能够见到的是`101 Switching Protocols`。它的意思是客户端使用 Upgrade 头字段，要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了

#### 2××

2××类状态码表示服务器收到并成功处理了客户端的请求，这也是客户端最愿意看到的状态码

`200 OK`是最常见的成功状态码，表示一切正常，服务器如客户端所期望的那样返回了处理结果，如果是非 HEAD 请求，通常在响应头后都会有 body 数据

`204 No Content`是另一个很常见的成功状态码，它的含义与“200 OK”基本相同，但响应头后没有 body 数据。所以对于 Web 服务器来说，正确地区分 200 和 204 是很必要的

`206 Partial Content`是 HTTP 分块下载或断点续传的基础，在客户端发送范围请求、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分

状态码 206 通常还会伴随着头字段`Content-Range`，表示响应报文里 body 数据的具体范围，供客户端确认，例如`Content-Range: bytes 0-99/2000`，意思是此次获取的是总计 2000 个字节的前 100 个字节

#### 3××

3××类状态码表示客户端请求的资源发生了变动，客户端必须用新的 URI 重新发送请求获取资源，也就是通常所说的重定向，包括著名的 301、302 跳转

- `301 Moved Permanently`俗称永久重定向，含义是此次请求的资源已经不存在了，需要改用新的 URI 再次访问
- `302 Found`，俗称临时重定向，意思是请求的资源还在，但需要暂时用另一个 URI 来访问
- `304 Not Modified` 它用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成重定向已到缓存的文件,即缓存重定向

301 和 302 都会在响应头里使用字段 Location 指明后续要跳转的 URI，最终的效果很相似，浏览器都会重定向到新的 URI。两者的根本区别在于语义，一个是永久，一个是临时，所以在场景、用法上差距很大

#### 4××

4××类状态码表示客户端发送的请求报文有误，服务器无法处理，它就是真正的错误码含义了

- `400 Bad Request`是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误。所以，在开发 Web 应用时应当尽量避免给客户端返回 400，而是要用其他更有明确含义的状态码
- `403 Forbidden`实际上不是客户端的请求出错，而是表示服务器禁止访问资源。原因可能多种多样，例如信息敏感、法律禁止等
- `404 Not Found`可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端
- `405 Method Not Allowed`不允许使用某些方法操作资源，例如不允许 POST 只能 GET
- `406 Not Acceptable`资源无法满足客户端请求的条件，例如请求中文但只有英文
- `408 Request Timeout`请求超时，服务器等待了过长的时间
- `409 Conflict`多个请求发生了冲突，可以理解为多线程并发时的竞态
- `413 Request Entity Too Large`请求报文里的 body 太大
- `414 Request-URI Too Long`请求行里的 URI 太大
- `429 Too Many Requests`客户端发送了太多的请求，通常是由于服务器的限连策略
- `431 Request Header Fields Too Large`请求头某个字段或总体太大


#### 5××

5××类状态码表示客户端请求报文正确，但服务器在处理时内部发生了错误，无法返回应有的响应数据，是服务器端的错误码

- `500 Internal Server Error`与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析
- `501 Not Implemented`表示客户端请求的功能还不支持
- `502 Bad Gateway`通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的
- `503 Service Unavailable`表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的**网络服务正忙，请稍后重试**的提示信息就是状态码 503

**503 是一个临时的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以 503 响应报文里通常还会有一个`Retry-After`字段，指示客户端可以在多久以后再次尝试发送请求**

### HTTP有哪些特点

- 灵活可扩展
- 可靠传输
- 应用层
- 请求-应答
- 无状态

HTTP 协议就随着互联网的发展一同成长起来了。在这个过程中，HTTP 协议逐渐增加了请求方法、版本号、状态码、头字段等特性。而 body 也不再限于文本形式的 TXT 或 HTML，而是能够传输图片、音频视频等任意数据，这些都是源于它的灵活可扩展的特点

#### 可靠传输

因为 HTTP 协议是基于 TCP/IP 的，而 TCP 本身是一个可靠的传输协议，所以 HTTP 自然也就继承了这个特性，能够在请求方和应答方之间可靠地传输数据

具体做法与 TCP/UDP 差不多，都是对实际传输的数据（entity）做了一层包装，加上一个头，然后调用 Socket API，通过 TCP/IP 协议栈发送或者接收

#### 应用层协议

在 TCP/IP 诞生后的几十年里，虽然出现了许多的应用层协议，但它们都仅关注很小的应用领域，局限在很少的应用场景。例如 FTP 只能传输文件、SMTP 只能发送邮件、SSH 只能远程登录等

HTTP 凭借着可携带任意头字段和实体数据的报文结构，以及连接控制、缓存代理等方便易用的特性，只要不太苛求性能，HTTP 几乎可以传递一切东西，满足各种需求，称得上是一个万能的协议

#### 请求-应答

这个请求 - 应答模式是 HTTP 协议最根本的通信模型，通俗来讲就是一发一收，有来有去

请求 - 应答模式也明确了 HTTP 协议里通信双方的定位，永远是请求方先发起连接和请求，是主动的，而应答方只有在收到请求后才能答复，是被动的，如果没有请求时不会有任何动作

请求方和应答方的角色也不是绝对的，在浏览器 - 服务器的场景里，通常服务器都是应答方，但如果将它用作代理连接后端服务器，那么它就可能同时扮演请求方和应答方的角色

请求 - 应答模式也完全符合 RPC（Remote Procedure Call）的工作模式，可以把 HTTP 请求处理封装成远程函数调用，导致了 WebService、RESTful 和 gRPC 等的出现

#### 无状态

状态其实就是客户端或者服务器里保存的一些数据或者标志，记录了通信过程中的一些变化信息

我们知道TCP 协议是有状态的，一开始处于 CLOSED 状态，连接成功后是 ESTABLISHED 状态，断开连接后是 FIN-WAIT 状态，最后又是 CLOSED 状态，这些状态就需要 TCP 在内部用一些数据结构去维护，可以简单地想象成是个标志量，标记当前所处的状态，例如 0 是 CLOSED，2 是 ESTABLISHED 等等

HTTP 在整个协议里没有规定任何的状态，客户端和服务器永远是处在一种无知的状态。建立连接前两者互不知情，每次收发的报文也都是互相独立的，没有任何的联系。收发报文也不会对客户端或服务器产生任何影响，连接后也不会要求保存任何信息

**无状态形象地来说就是没有记忆能力**。比如，浏览器发了一个请求，说【我是小明，请给我 A 文件】，服务器收到报文后就会检查一下权限，看小明确实可以访问 A 文件，于是把文件发回给浏览器。接着浏览器还想要 B 文件，但服务器不会记录刚才的请求状态，不知道第二个请求和第一个请求是同一个浏览器发来的，所以浏览器必须还得重复一次自己的身份才行：【我是刚才的小明，请再给我 B 文件】

我们可以再对比一下 UDP 协议，不过它是**无连接也无状态**的，顺序发包乱序收包，数据包发出去后就不管了，收到后也不会顺序整理。而 HTTP 是**有连接无状态**，顺序发包顺序收包，按照收发的顺序管理报文

**HTTP 是灵活可扩展的，虽然标准里没有规定状态，但完全能够在协议的框架里给它打个补丁，增加这个特性**


HTTP 协议其他的特点，例如传输的实体数据可缓存可压缩、可分段获取数据、支持身份认证、支持国际化语言等


### HTTP优缺点

HTTP 协议里的请求方法、URI、状态码、原因短语、头字段等每一个核心组成要素都没有被写死，允许开发者任意定制、扩充或解释，给予了浏览器和服务器最大程度的信任和自由

几乎所有的编程语言都有 HTTP 调用库和外围的开发测试工具

无状态表示服务器都是相同的，没有状态的差异，所以可以很容易地组成集群，让负载均衡把请求转发到任意一台服务器，不会因为状态不一致导致处理出错

服务器没有记忆能力，它就无法支持需要连续多个步骤的事务操作。例如电商购物，首先要登录，然后添加购物车，再下单、结算、支付，这一系列操作都需要知道用户的身份才行，但“无状态”服务器是不知道这些请求是相互关联的，每次都得问一遍身份信息，不仅麻烦，而且还增加了不必要的数据传输量

HTTP 是明文传输，明文意思就是协议里的报文（准确地说是 header 部分）不使用二进制数据，而是用简单可阅读的文本形式

对比 TCP、UDP 这样的二进制协议，它的优点显而易见，不需要借助任何外部工具，用浏览器、Wireshark 或者 tcpdump 抓包后，直接用肉眼就可以很容易地查看或者修改，为我们的开发调试工作带来极大的便利

---------------------------------------------

### HTTP 的实体数据

MIME 是一个很大的标准规范，但 HTTP 只取了其中的一部分，用来标记 body 的数据类型，这就是我们平常总能听到的`MIME type`

MIME 把数据分成了八大类，每个大类下再细分出多个子类，形式是`type/subtype`的字符串，刚好也符合了 HTTP 明文的特点，所以能够很容易地纳入 HTTP 头字段里

这里列举一下在 HTTP 里经常遇到的几个类别:

- text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等
- image：即图像文件，有 image/gif、image/jpeg、image/png 等
- audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等
- application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，就会是 application/octet-stream，即不透明的二进制数据

但仅有 MIME type 还不够，因为 HTTP 在传输时为了节约带宽，有时候还会压缩数据，为了不要让浏览器继续猜，还需要有一个`Encoding type`，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据

比起 MIME type 来说，Encoding type 就少了很多，常用的只有下面三种：
- gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式
- deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip
- br：一种专门为 HTTP 优化的新压缩算法（Brotli）

#### 数据类型使用的头字段

有了 MIME type 和 Encoding type，无论是浏览器还是服务器就都可以轻松识别出 body 的类型，也就能够正确处理数据了

HTTP 协议为此定义了两个 `Accept` 请求头字段和两个 `Content` 实体头字段，用于客户端和服务器进行“内容协商”。也就是说，客户端用 `Accept` 头告诉服务器希望接收什么样的数据，而服务器用 `Content` 头告诉客户端实际发送了什么样的数据

```
GET / HTTP/1.1
Host: www.ifcalm.net
Accept: text/html, application/xml, image/webp, image/png
Accept-Encoding: gzip, deflate, br
```

Accept 字段标记的是客户端可理解的 MIME type，可以用“,”做分隔符列出多个类型，让服务器有更多的选择余地`Accept: text/html,application/xml,image/webp,image/png`

服务器会在响应报文里用头字段 Content-Type 告诉实体数据的真实类型`Content-Type: text/html`

Accept-Encoding 字段标记的是客户端支持的压缩格式，例如上面说的 gzip、deflate 等，同样也可以用“,”列出多个，服务器可以选择其中一种来压缩数据，实际使用的压缩格式放在响应头字段 Content-Encoding 里
```
Accept-Encoding: gzip, deflate, br
Content-Encoding: gzip
```

不过这两个字段是可以省略的，如果请求报文里没有 Accept-Encoding 字段，就表示客户端不支持压缩数据；如果响应报文里没有 Content-Encoding 字段，就表示响应数据没有被压缩

#### 语言类型与编码

所谓的语言类型就是人类使用的自然语言，例如英语、汉语、日语等，而这些自然语言可能还有下属的地区性方言，所以在需要明确区分的时候也要使用`type-subtype`的形式，不过这里的格式与数据类型不同，分隔符不是`/`，而是`-`

举几个例子：en 表示任意的英语，en-US 表示美式英语，en-GB 表示英式英语，而 zh-CN 就表示我们最常使用的汉语

Unicode 和 UTF-8，把世界上所有的语言都容纳在一种编码方案里，遵循 UTF-8 字符编码方式的 Unicode 字符集也成为了互联网上的标准字符集

#### 语言类型使用的头字段

Accept-Language 字段标记了客户端可理解的自然语言，也允许用`,`做分隔符列出多个类型，例如:
```
Accept-Language: zh-CN, zh, en
```

服务器应该在响应报文里用头字段 Content-Language 告诉客户端实体数据使用的实际语言类型:
```
Content-Language: zh-CN
```

字符集在 HTTP 里使用的请求头字段是 `Accept-Charset`，但响应头里却没有对应的 `Content-Charset`，而是在 `Content-Type` 字段的数据类型后面用`charset=xxx`来表示，这点需要特别注意

```
Accept-Charset: gbk, utf-8Content-Type: text/html; charset=utf-8
```

#### 内容协商的质量值

在 HTTP 协议里用 Accept、Accept-Encoding、Accept-Language 等请求头字段进行内容协商的时候，还可以用一种特殊的“`q`参数表示权重来设定优先级，这里的`q`是quality factor的意思

权重的最大值是 1，最小值是 0.01，默认值是 1，如果值是 0 就表示拒绝。具体的形式是在数据类型或语言代码后面加一个`;`，然后是`q=value`

这里要提醒的是`;`的用法，在大多数编程语言里`;`的断句语气要强于`,`，而在 HTTP 的内容协商里却恰好反了过来，`;`的意义是小于`,`的

```
Accept: text/html,application/xml;q=0.9,*/*;q=0.8
```

它表示浏览器最希望使用的是 HTML 文件，权重是 1，其次是 XML 文件，权重是 0.9，最后是任意数据类型，权重是 0.8。服务器收到请求头后，就会计算权重，再根据自己的实际情况优先输出 HTML 或者 XML

#### 内容协商的结果

内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。但有的时候，服务器会在响应头里多加一个 Vary 字段，记录服务器在内容协商时参考的请求头字段，给出一点信息，例如：
```
Vary: Accept-Encoding,User-Agent,Accept
```

这个 Vary 字段表示服务器依据了 Accept-Encoding、User-Agent 和 Accept 这三个头字段，然后决定了发回的响应报文

Vary 字段可以认为是响应报文的一个特殊的“版本标记”。每当 Accept 等请求头变化时，Vary 也会随着响应报文一起变化。也就是说，同一个 URI 可能会有多个不同的“版本”，主要用在传输链路中间的代理服务器实现缓存服务


### HTTP传输大文件的方法

- 数据压缩
- 分块传输
- 范围请求
- 多段数据

#### 数据压缩

通常浏览器在发送请求时都会带着`Accept-Encoding`头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进`Content-Encoding`响应头里，再把原数据压缩后发给浏览器

如果压缩率能有 50%，也就是说 100K 的数据能够压缩成 50K 的大小，那么就相当于在带宽不变的情况下网速提升了一倍，加速的效果是非常明显的

不过这个解决方法也有个缺点，gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小,甚至还有可能会增大一点，所以它就失效了

不过数据压缩在处理文本的时候效果还是很好的，所以各大网站的服务器都会使用这个手段作为保底

#### 分块传输

压缩是把大文件整体变小，我们可以反过来思考，如果大文件整体不能变小，那就把它拆开，分解成多个小块，把这些小块分批发给浏览器，浏览器收到后再组装复原

这种化整为零的思路在 HTTP 协议里就是`chunked`分块传输编码，在响应报文里用头字段`Transfer-Encoding: chunked`来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块逐个发送

**`Transfer-Encoding: chunked`和`Content-Length`这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知，这一点你一定要记住**

分块传输的编码规则:
- 每个分块包含两个部分，长度头和数据块
- 长度头是以 CRLF（回车换行，即\r\n）结尾的一行明文，用 16 进制数字表示长度
- 数据块紧跟在长度头后，最后也用 CRLF 结尾，但数据不包含 CRLF
- 最后用一个长度为 0 的块表示结束，即`0\r\n\r\n`

浏览器在收到分块传输的数据后会自动按照规则去掉分块编码，重新组装出内容，所以想要看到服务器发出的原始报文形态就得用 Telnet 手工发送请求, 或者用 Wireshark 抓包

#### 范围请求

有了分块传输编码，服务器就可以轻松地收发大文件了，但对于上 G 的超大文件，还有一些问题需要考虑, 比如，你在看当下正热播的某穿越剧，想跳过片头，直接看正片，或者有段剧情很无聊，想拖动进度条快进几分钟，这实际上是想获取一个大文件其中的片段数据，而分块传输并没有这个能力

HTTP 协议为了满足这样的需求，提出了`范围请求`的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分

范围请求不是 Web 服务器必备的功能，可以实现也可以不实现，所以服务器必须在响应头里使用字段`Accept-Ranges: bytes`明确告知客户端：我是支持范围请求的

服务器可以发送`Accept-Ranges: none`，或者干脆不发送`Accept-Ranges`字段，这样客户端就认为服务器没有实现范围请求功能

请求头 `Range` 是 HTTP 范围请求的专用字段，格式是`bytes=x-y`，其中的 x 和 y 是以字节为单位的数据范围

要注意 x、y 表示的是偏移量，范围必须从 0 计数，例如前 10 个字节表示为`0-9`，第二个 10 字节表示为`10-19`，而`0-10`实际上是前 11 个字节

`Range` 的格式也很灵活，起点 x 和终点 y 可以省略，能够很方便地表示正数或者倒数的范围。假设文件是 100 个字节，那么:
- `0-`表示从文档起点到文档终点，相当于`0-99`，即整个文件
- `10-`是从第 10 个字节开始到文档末尾，相当于`10-99`
- `-1`是文档的最后一个字节，相当于`99-99`
- `-10`是从文档末尾倒数 10 个字节，相当于`90-99`

服务器收到 Range 字段后，需要做四件事:
- 它必须检查范围是否合法，比如文件只有 100 个字节，但请求`200-300`，这就是范围越界了。服务器就会返回状态码 `416`，意思是你的范围请求有误，我无法处理，请再检查一下
- 如果范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码`206 Partial Content`，和 200 的意思差不多，但表示 body 只是原数据的一部分
- 服务器要添加一个响应头字段 `Content-Range`，告诉片段的实际偏移量和资源的总大小，格式是`bytes x-y/length`，范围后多了总长度。例如，对于`0-10`的范围请求，值就是`bytes 0-10/100`
- 把片段用 TCP 发给客户端，一个范围请求就算是处理完了


有了范围请求之后，HTTP 处理大文件就更加轻松了，看视频时可以根据时间点计算出文件的 Range，不用下载整个文件，直接精确获取片段所在的数据内容

不仅看视频的拖拽进度需要范围请求，常用的下载工具里的多段下载、断点续传也是基于它实现的，要点是:
- 先发个 `HEAD`，看服务器是否支持范围请求，同时获取文件的大小
- 开 N 个线程，每个线程使用 Range 字段划分出各自负责下载的片段，发请求传输数据
- 下载意外中断也不怕，不必重头再来一遍，只要根据上次的下载记录，用 Range 请求剩下的那一部分就可以了


#### 多段数据

刚才说的范围请求一次只获取一个片段，其实它还支持在 Range 头里使用多个`x-y`，一次性获取多个片段数据

这种情况需要使用一种特殊的 MIME 类型：`multipart/byteranges`，表示报文的 body 是由多段字节序列组成的，并且还要用一个参数`boundary=xxx`给出段之间的分隔标记

多段数据的格式与分块传输也比较类似，但它需要用分隔标记 `boundary` 来区分不同的片段

```
GET /16-2 HTTP/1.1
Host: www.ifcalm.net
Range: bytes=0-9, 20-29
```

### HTTP 的连接管理

#### 短连接

HTTP 协议最初（0.9/1.0）是个非常简单的协议，通信过程也采用了简单的`请求 - 应答`方式, 它底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接

因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为短连接。早期的 HTTP 协议也被称为是无连接的协议

短连接的缺点相当严重，因为在 TCP 协议里，建立连接和关闭连接都是非常昂贵的操作。TCP 建立连接要有**三次握手**，发送 3 个数据包，需要 1 个 RTT；关闭连接是**四次挥手**，4 个数据包需要 2 个 RTT

#### 长连接

针对短连接暴露出的缺点，HTTP 协议就提出了**长连接**的通信方式，也叫持久连接（persistent connections）、连接保活（keep alive）、连接复用（connection reuse）

其实解决办法也很简单，用的就是成本均摊的思路，既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个`请求 - 应答`均摊到多个`请求 - 应答`上

#### 连接相关的头字段

由于长连接对性能的改善效果非常显著，所以在 `HTTP/1.1` 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接，在这个连接上收发数据

当然，我们也可以在请求头里明确地要求使用长连接机制，使用的字段是 `Connection`，值是`keep-alive`

不过不管客户端是否显式要求长连接，如果服务器支持长连接，它总会在响应报文里放一个`Connection: keep-alive`字段，告诉客户端：我是支持长连接的，接下来就用这个 TCP 一直收发数据吧


因为 TCP 连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务

在客户端，可以在请求头里加上`Connection: close`字段，告诉服务器：这次通信后就关闭连接。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接

服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 Nginx 来举例，它有两种方式:
- 使用`keepalive_timeout`指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源
- 使用`keepalive_requests`指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接


#### 队头阻塞

**队头阻塞**与短连接和长连接无关，而是由 HTTP 基本的`请求-应答`模型所导致的

**因为 HTTP 规定报文必须是一发一收，这就形成了一个先进先出的串行队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理**

如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本

#### 性能优化

因为`请求-应答`模型不能变，所以队头阻塞问题在 `HTTP/1.1` 里无法解决，只能缓解

这在 HTTP 里就是并发连接（concurrent connections），也就是同时对一个域名发起多个长连接，用数量来解决质量的问题

但这种方式也存在缺陷。如果每个客户端都想自己快，建立很多个连接，用户数×并发数就会是个天文数字。服务器的资源根本就扛不住，或者被服务器认为是恶意攻击，反而会造成拒绝服务

**域名分片**技术，还是用数量来解决质量的思路, HTTP 协议和浏览器不是限制并发连接数量吗？那我们就多开几个域名


### HTTP的重定向和跳转

301 是永久重定向，302 是临时重定向，浏览器收到这两个状态码就会跳转到新的 URI

浏览器收到 301/302 报文，会检查响应头里有没有`Location`。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求，相当于自动替我们点击了这个链接

在`Location`里的 URI 既可以使用绝对 URI，也可以使用相对 URI。所谓绝对 URI，就是完整形式的 URI，所谓相对 URI，就是省略了 scheme 和 host:port，只有 path 和 query 部分，是不完整的，但可以从请求上下文里计算得到

**在重定向时如果只是在站内跳转，你可以放心地使用相对 URI。但如果要跳转到站外，就必须用绝对 URI**

#### 重定向状态码

`301` 俗称永久重定向（Moved Permanently），意思是原 URI 已经永久性地不存在了，今后的所有请求都必须改用新的 URI, 浏览器看到 301，就知道原来的 URI过时了，就会做适当的优化。比如历史记录、更新书签，下次可能就会直接用新的 URI 访问，省去了再次跳转的成本。搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI

`302` 俗称临时重定向（Moved Temporarily），意思是原 URI 处于临时维护状态，新的 URI 是起临时作用的，浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，所以只会执行简单的跳转页面，不记录新的 URI，也不会有其他的多余动作，下次访问还是用原 URI

#### 重定向的相关问题

- 性能损耗, 很明显，重定向的机制决定了一个跳转会有两次请求 - 应答，比正常的访问多了一次, 虽然 301/302 报文很小，但大量的跳转对服务器的影响也是不可忽视的。站内重定向还好说，可以长连接复用，站外重定向就要开两个连接，如果网络连接质量差，那成本可就高多了，会严重影响用户的体验
- 循环跳转, 如果重定向的策略设置欠考虑，可能会出现`A=>B=>C=>A`的无限循环，不停地在这个链路里转圈圈, 所以 HTTP 协议特别规定，浏览器必须具有检测循环跳转的能力，在发现这种情况时应当停止发送请求并给出错误提示


### HTTP的Cookie机制

HTTP 是无状态的，这既是优点也是缺点。优点是服务器没有状态差异，可以很容易地组成集群，而缺点就是无法支持需要记录状态的事务操作

HTTP 协议是可扩展的，后来发明的 Cookie 技术，给 HTTP 增加了记忆能力

#### 什么是 Cookie

如果 Web 服务器只是用来管理静态文件还好说，对方是谁并不重要，把文件从磁盘读出来发走就可以了。但随着 HTTP 应用领域的不断扩大，对记忆能力的需求也越来越强烈。比如网上论坛、电商购物，都需要看客下菜，只有记住用户的身份才能执行发帖子、下订单等一系列会话事务

HTTP 的 Cookie 机制，既然服务器记不住，那就在外部想办法记住。相当于是服务器给每个客户端都贴上一张小纸条，上面写了一些只有服务器才能理解的数据，需要的时候客户端把这些信息发给服务器，服务器看到 Cookie，就能够认出对方是谁了

#### Cookie 的工作过程

Cookie 是怎么传递的呢, 这要用到两个字段：响应头字段 `Set-Cookie` 和请求头字段 `Cookie`

当用户通过浏览器第一次访问服务器的时候，服务器肯定是不知道他的身份的。所以，就要创建一个独特的身份标识数据，格式是`key=value`，然后放进 `Set-Cookie` 字段里，随着响应报文一同发给浏览器

浏览器收到响应报文，看到里面有 `Set-Cookie`，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进 `Cookie` 字段里发给服务器, 因为第二次请求里面有了 `Cookie` 字段，服务器就知道这个用户不是新人，之前来过，就可以拿出 `Cookie` 里的值，识别出用户的身份，然后提供个性化的服务

服务器有时会在响应头里添加多个 `Set-Cookie`，存储多个`key=value`。但浏览器这边发送时不需要用多个 `Cookie` 字段，只要在一行里用`;`隔开就行

`Cookie` 是由浏览器负责存储的，而不是操作系统。所以，它是浏览器绑定的，只能在本浏览器内生效

#### Cookie 的属性

Cookie 就是服务器委托浏览器存储在客户端里的一些数据，而这些数据通常都会记录用户的关键识别信息, 所以，就需要在`key=value`外再用一些手段来保护，防止外泄或窃取，这些手段就是 `Cookie` 的属性

首先，我们应该设置 `Cookie` 的生存周期，也就是它的有效期，让它只能在一段时间内可用，一旦超过这个期限浏览器就认为是 `Cookie` 失效，在存储里删除，也不会发送给服务器

`Cookie` 的有效期可以使用 `Expires` 和 `Max-Age` 两个属性来设置
- `Expires` 俗称过期时间，用的是绝对时间点，可以理解为截止日期
- `Max-Age` 用的是相对时间，单位是秒，浏览器用收到报文的时间点再加上 Max-Age，就可以得到失效的绝对时间

`Expires` 和 `Max-Age` 可以同时出现，两者的失效时间可以一致，也可以不一致，但浏览器会优先采用 `Max-Age` 计算失效期

其次，我们需要设置 `Cookie` 的作用域，让浏览器仅发送给特定的服务器和 URI，避免被其他网站盗用

作用域的设置比较简单，`Domain`和`Path`指定了 Cookie 所属的域名和路径，浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie

最后要考虑的就是 **Cookie 的安全性**了，尽量不要让服务器以外的人看到

- 属性`HttpOnly`会告诉浏览器，此 Cookie 只能通过浏览器 HTTP 协议传输，禁止其他方式访问，浏览器的 JS 引擎就会禁用 `document.cookie` 等一切相关的 API，脚本攻击也就无从谈起了
- 另一个属性`SameSite`可以防范跨站请求伪造（XSRF）攻击，设置成`SameSite=Strict`可以严格限定 Cookie 不能随着跳转链接跨站发送
- 还有一个属性叫`Secure`，表示这个 Cookie 仅能用 HTTPS 协议加密传输，明文的 HTTP 协议会禁止发送。但 Cookie 本身不是加密的，浏览器里还是以明文的形式存在


#### Cookie 的应用

Cookie 最基本的一个用途就是身份识别，保存用户的登录信息，实现会话事务

Cookie 的另一个常见用途是广告跟踪


### HTTP的缓存控制

缓存（Cache）是计算机领域里的一个重要概念，是优化系统性能的利器

HTTP 传输的每一个环节基本上都会有缓存，非常复杂, 基于`请求-应答`模式的特点，可以大致分为客户端缓存和服务器端缓存

#### 服务器缓存控制

服务器标记资源有效期使用的头字段是`Cache-Control`，里面的值`max-age=30`就是资源的有效时间，相当于告诉浏览器，这个页面只能缓存 30 秒，之后就算是过期，不能用

这里的 max-age 是生存时间，时间的计算起点是响应报文的创建时刻，而不是客户端收到报文的时刻，也就是说包含了在链路传输过程中所有节点所停留的时间

`max-age`是 HTTP 缓存控制最常用的属性，此外在响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存:
- no-store：不允许缓存，用于某些变化非常频繁的数据，例如秒杀页面
- no-cache：它的字面含义容易与 no-store 搞混，实际的意思并不是不允许缓存，而是可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本
- must-revalidate：又是一个和 no-cache 相似的词，它的意思是如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证


#### 客户端的缓存控制

其实不止服务器可以发`Cache-Control`头，浏览器也可以发`Cache-Control`，也就是说请求-应答的双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略

当你点刷新按钮的时候，浏览器会在请求头里加一个`Cache-Control: max-age=0`。因为 max-age 是生存时间，max-age=0 的意思就是, 我要一个最最新的数据，而本地缓存里的数据至少保存了几秒钟，所以浏览器就不会使用缓存，而是向服务器发请求。服务器看到 max-age=0，也就会用一个最新生成的报文回应浏览器

Ctrl+F5 的强制刷新，其实是发了一个`Cache-Control: no-cache`，含义和`max-age=0` 基本一样，就看后台的服务器怎么理解，通常两者的效果是相同的

#### 条件请求

HTTP 协议就定义了一系列`If`开头的条件请求字段，专门用来检查验证资源是否过期，把两个请求才能完成的工作合并在一个请求里做。而且，验证的责任也交给服务器

条件请求一共有 5 个头字段，我们最常用的是:
- if-Modified-Since
- If-None-Match

需要第一次的响应报文预先提供`Last-modified`和`ETag`，然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的

如果资源没有变，服务器就回应一个`304 Not Modified`，表示缓存依然有效，浏览器就可以更新一下有效期，然后放心大胆地使用缓存了

- `Last-modified` 就是文件的最后修改时间
- `ETag` 是实体标签（Entity Tag）的缩写，是资源的一个唯一标识，主要是用来解决修改时间无法准确区分文件变化的问题


### HTTP的代理服务

引入 HTTP 代理后，原来简单的双方通信就变复杂了一些，加入了一个或者多个中间人，但整体上来看，还是一个有顺序关系的链条，而且链条里相邻的两个角色仍然是简单的一对一通信，不会出现越级的情况

链条的起点还是客户端, 也就是浏览器，中间的角色被称为代理服务器（proxy server），链条的终点被称为源服务器（origin server）

#### 代理服务

所谓的代理服务就是指服务本身不生产内容，而是处于中间位置转发上下游的请求和响应，具有双重身份，面向下游的用户时，表现为服务器，代表源服务器响应客户端的请求；而面向上游的源服务器时，又表现为客户端，代表客户端发送请求

- 匿名代理
- 透明代理
- 正向代理
- 反向代理

#### 代理的作用

**计算机科学领域里的任何问题，都可以通过引入一个中间层来解决**

由于代理处在 HTTP 通信过程的中间位置，相应地就对上屏蔽了真实客户端，对下屏蔽了真实服务器，在这个中间层里就可以做很多的事情，为 HTTP 协议增加更多的灵活性，实现客户端和服务器的双赢

代理最基本的一个功能是负载均衡。因为在面向客户端时屏蔽了源服务器，客户端看到的只是代理服务器，源服务器究竟有多少台、是哪些 IP 地址都不知道。于是代理服务器就可以掌握请求分发的权力，决定由后面的哪台服务器来响应请求


代理中常用的负载均衡算法你应该也有所耳闻吧，比如轮询、一致性哈希等等，这些算法的目标都是尽量把外部的流量合理地分散到多台源服务器，提高系统的整体资源利用率和性能

在负载均衡的同时，代理服务还可以执行更多的功能：
- 健康检查：使用心跳等机制监控后端服务器，发现有故障就及时踢出集群，保证服务高可用
- 安全防护：保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载
- 数据过滤：拦截上下行的数据，任意指定策略修改请求或者响应
- 内容缓存：暂存、复用服务器响应


#### 代理相关头字段

代理服务器需要用字段`Via`标明代理的身份

`Via` 是一个通用字段，请求头或响应头里都可以出现。每当报文经过一个代理节点，代理服务器就会把自身的信息追加到字段的末尾

如果通信链路中有很多中间代理，就会在 `Via` 里形成一个链表，这样就可以知道报文究竟走过了多少个环节才到达了目的地

假设客户端发送请求会经过这两个代理，依次添加就是`Via: proxy1, proxy2`，等到服务器返回响应报文的时候就要反过来走，头字段就是`Via: proxy2, proxy1`

`Via` 字段只解决了客户端和源服务器判断是否存在代理的问题，还不能知道对方的真实信息. 但服务器的 IP 地址应该是保密的，关系到企业的内网安全，所以一般不会让客户端知道。不过反过来，通常服务器需要知道客户端的真实 IP 地址，方便做访问控制、用户画像、统计分析

可惜的是 HTTP 标准里并没有为此定义头字段，但已经出现了很多事实上的标准，最常用的两个头字段是`X-Forwarded-For`和`X-Real-IP`

- `X-Forwarded-For`的字面意思是为谁而转发，形式上和`Via`差不多，也是每经过一个代理节点就会在字段里追加一个信息。但`Via`追加的是代理主机名或者域名，而`X-Forwarded-For`追加的是请求方的 IP 地址。所以，在字段里最左边的 IP 地址就是客户端的地址
- `X-Real-IP`是另一种获取客户端真实 IP 的手段，它的作用很简单，就是记录客户端 IP 地址，没有中间的代理信息，相当于是`X-Forwarded-For`的简化版。如果客户端和源服务器之间只有一个代理，那么这两个字段的值就是相同的


#### 代理协议

有了`X-Forwarded-For`等头字段，源服务器就可以拿到准确的客户端信息了。但对于代理服务器来说它并不是一个最佳的解决方案。因为通过`X-Forwarded-For`操作代理信息必须要解析 HTTP 报文头，这对于代理来说成本比较高，原本只需要简单地转发消息就好，而现在却必须要费力解析数据再修改数据，会降低代理的转发性能。另一个问题是`X-Forwarded-For`等头必须要修改原始报文，而有些情况下是不允许甚至不可能的, 比如使用 HTTPS 通信被加密

所以就出现了一个专门的代理协议，它由知名的代理软件 HAProxy 所定义，也是一个事实标准，被广泛采用

代理协议有 v1 和 v2 两个版本，v1 和 HTTP 差不多，也是明文，而 v2 是二进制格式。v1版本它在 HTTP 报文前增加了一行 `ASCII` 码文本，相当于又多了一个头

这一行文本其实非常简单，开头必须是`PROXY`五个大写字母，然后是`TCP4`或者`TCP6`，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行`\r\n`结束

```
PROXY TCP4 1.1.1.1 2.2.2.2 55555 80\r\n
GET / HTTP/1.1\r\n
Host: www.xxx.com\r\n
\r\n
```

服务器看到这样的报文，只要解析第一行就可以拿到客户端地址，不需要再去理会后面的 HTTP 数据，省了很多事情


### HTTP的缓存代理

代理服务收到源服务器发来的响应数据后需要做两件事。第一个当然是把报文转发给客户端，而第二个就是把报文存入自己的 Cache 里

下一次再有相同的请求，代理服务器就可以直接发送 304 或者缓存数据，不必再从源服务器那里获取。这样就降低了客户端的等待时间，同时节约了源服务器的网络带宽


------------------------------------------------------


### HTTPS是什么？SSL/TLS又是什么？

由于 HTTP 天生明文的特点，整个传输过程完全透明，任何人都能够在链路中截获、修改或者伪造请求/响应报文，数据不具有可信性

比如代理服务，它作为 HTTP 通信的中间人，在数据上下行的时候可以添加或删除部分头字段，也可以使用黑白名单过滤 body 里的关键字，甚至直接发送虚假的请求、响应，而浏览器和源服务器都没有办法判断报文的真伪

#### 什么是安全

- 机密性: 是指对数据的保密，只能由可信的人访问，对其他人是不可见的秘密，简单来说就是不能让不相关的人看到不该看的东西
- 完整性: 是指数据在传输过程中没有被篡改，不多也不少，完完整整地保持着原状
- 身份认证: 指确认对方的真实身份，也就是证明你真的是你，保证消息只能发送给可信的人
- 不可否认: 也叫不可抵赖，意思是不能否认已经发生过的行为

#### 什么是 HTTPS

HTTPS它为 HTTP 增加了上面所说的四大安全特性

HTTPS 其实是一个非常简单的协议，RFC 文档很小，里面规定了新的协议名`https`，默认端口号 `443`，至于其他的什么请求 - 应答模式、报文结构、请求方法、URI、头字段、连接管理等等都完全沿用 HTTP，没有任何新的东西

也就是说，除了协议名`http`和端口号 80 这两点不同，HTTPS 协议在语法、语义上和 HTTP 完全一样

HTTPS 与 HTTP 最大的区别，就是它能够鉴别危险的网站，并且尽最大可能保证你的上网安全，防御黑客对信息的窃听、篡改或者钓鱼、伪造

HTTPS 它把 HTTP 下层的传输协议由 TCP/IP 换成了 SSL/TLS，由`HTTP over TCP/IP`变成了`HTTP over SSL/TLS`，让 HTTP 运行在了安全的 SSL/TLS 协议上，收发报文不再使用 Socket API，而是调用专门的安全接口

#### SSL/TLS

SSL 即安全套接层（Secure Sockets Layer），在 OSI 模型中处于第 5 层会话层

TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成，综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术

浏览器和服务器在使用 TLS 建立连接时需要选择一组恰当的加密算法来实现安全通信，这些算法的组合被称为密码套件

#### OpenSSL

说到 TLS，就不能不谈到 OpenSSL，它是一个著名的开源密码学程序库和工具包，几乎支持所有公开的加密算法和协议，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，包括常用的 Web 服务器 Apache、Nginx 等

--------------------------------------------------------

### 对称加密与非对称加密

