## 本文纲要

数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法，数据结构是为算法服务的，算法要作用在特定的数据结构之上

学习一种技术的思路:

1. 该技术产生的背景
2. 该技术有什么特点
3. 适合解决什么问题
4. 实际的应用场景

### 常用的数据结构

- 数组
- 链表
- 栈
- 队列
- 散列表
- 二叉树
- 堆
- 跳表
- 图
- Trie 树, 又称 字典树


### 常用的算法

- 排序算法
- 搜索算法
- 递归
- 二分查找
- 哈希算法
- 贪心算法
- 分治算法
- 回溯法
- 动态规划
- 字符串匹配算法

### 数据结构操作

- 查找
- 插入
- 删除

-----------------------------------------------

## 复杂度分析

数据结构和算法本身解决的是**快**和**省**的问题，即如何让代码运行得更快，如何让代码更省存储空间

### 时间复杂度

#### 大O表示法

大O时间复杂度不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势

当 n 很大时，代码执行次数公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了

#### 复杂度分析原则

- 只关注循环执行次数最多的一段代码
- 加法法则：总复杂度等于量级最大的那段代码的复杂度
- 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

#### 常见的复杂度量级

- 常量阶, O(1)
- 对数阶, O(logn)
- 线性阶, O(n)
- 线性对数阶, O(nlogn)
- 平方阶, O(n^2)
- 指数阶, O(2^n)
- 阶乘, O(n!)

`O(1)`只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码, 一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是`Ο(1)`


### 空间复杂度

时间复杂度表示算法的执行时间与数据规模之间的增长关系, 空间复杂度表示算法使用的存储空间与数据规模之间的增长关系

### 特殊复杂度

- 最好情况时间复杂度
- 最坏情况时间复杂度
- 平均情况时间复杂度
- 均摊时间复杂度


最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度

---------------------------------------

## 数组

在每一种编程语言中，基本都会有数组这种数据类型。不过，它不仅仅是一种编程语言中的数据类型，还是一种最基础的数据结构

### 数组的随机访问

数组是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据

- 线性
- 连续的内存空间
- 相同的数据类型

计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过的寻址公式，计算出该元素存储的内存地址

**数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)**

数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 `O(n)`

-----------------------------------------------

## 链表

链表并不需要一块连续的内存空间，它通过**指针**将一组零散的内存块串联起来使用

- 单链表
- 双链表
- 循环链表
- 双向循环链表

在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 `O(n)`。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的

### 单链表

单链表中有两个结点是比较特殊的，分别是第一个结点和最后一个结点。把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址，表示这是链表上最后一个结点


### 循环链表

循环链表是一种特殊的单链表，它跟单链表唯一的区别就在尾结点，单链表的尾结点指针指向空地址，表示这就是最后的结点了，而循环链表的尾结点指针是指向链表的头结点

### 双向链表

单向链表只有一个方向，结点只有一个后继指针 `next` 指向后面的结点。而双向链表, 它支持两个方向，每个结点不止有一个后继指针 `next` 指向后面的结点，还有一个前驱指针 `prev` 指向前面的结点

双向链表可以支持 `O(1)` 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效

### 空间换时间

当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路

### 链表代码的书写

- 理解指针是存储所指对象的内存地址
- 警惕指针丢失
- 利用哨兵简化实现难度，哨兵是解决边界问题的
- 重点留意边界条件处理


将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量

-----------------------------------------

## 栈

后进者先出，先进者后出，这就是典型的栈结构，栈是一种操作受限的线性表，只允许在一端插入和删除数据

栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈


### 栈操作

- 入栈, 在栈顶插入一个数据
- 出栈, 从栈顶删除一个数据

### 栈的时间复杂读

在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是 `O(1)`

### 栈的应用

比较经典的一个应用场景就是**函数调用栈**

操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成**栈**这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈

### 栈总结

栈是一种操作受限的数据结构，只支持入栈和出栈操作。后进先出是它最大的特点。栈既可以通过数组实现，也可以通过链表来实现。不管基于数组还是链表，入栈、出栈的时间复杂度都为 `O(1)`

----------------------------------------

## 队列

先进者先出，这就是典型的**队列**, 队列跟栈一样，也是一种操作受限的线性表数据结构

### 队列操作

- 入队, 放一个数据到队列尾部
- 出队, 从队列头部取一个元素

### 队列的实现

跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的栈叫作顺序栈，用链表实现的栈叫作链式栈。同样，用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列

对于栈来说，我们只需要一个**栈顶指针**就可以了。但是队列需要两个指针：一个是 `head` 指针，指向队头；一个是 `tail` 指针，指向队尾

**确定好队空和队满的判定条件**

### 队列的应用

- 阻塞队列
- 并发队列
- 循环队列


-------------------------------------------------------

## 递归

- 一个问题的解可以分解为几个子问题的解
- 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
- 存在递归终止条件

写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码

### 递归注意事项

#### 递归代码要警惕堆栈溢出

函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险

#### 递归代码要警惕重复计算

为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经求解过的 `f(x)`。当递归调用到 `f(x)` 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回，不需要重复计算，这样就能避免刚讲的问题了

### 递归的效率

在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销


### 非递归代码

递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；而弊就是空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题。所以，在开发过程中，我们要根据实际情况来选择是否需要用递归的方式来实现

所有的递归代码都可以改为这种迭代循环的非递归写法，因为递归本身就是借助栈来实现的，只不过我们使用的栈是系统或者虚拟机本身提供的，我们没有感知罢了。如果我们自己在内存堆上实现栈，手动模拟入栈、出栈过程，这样任何递归代码都可以改写成看上去不是递归代码的样子


-----------------------------------------

## 排序

大部分编程语言中，也都提供了排序函数。在平常的项目中，我们也经常会用到排序。排序非常重要

- 冒泡排序
- 插入排序
- 选择排序
- 归并排序
- 快速排序
- 计数排序
- 基数排序
- 桶排序

### 排序算法的操作

- 比较
- 交换

### 排序算法的效率

- 最好情况、最坏情况、平均情况时间复杂度
- 时间复杂度的系数、常数 、低阶
- 比较次数和交换次数


原地排序算法，就是特指空间复杂度是 `O(1)` 的排序算法

稳定性: 如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变


### 冒泡排序

冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作

冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 `O(1)`，是一个原地排序算法

在冒泡排序中，只有交换才可以改变两个元素的前后顺序。为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法

最好情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡操作，就可以结束了，所以最好情况时间复杂度是 `O(n)`。而最坏的情况是，要排序的数据刚好是倒序排列的，我们需要进行 n 次冒泡操作，所以最坏情况时间复杂度为 `O(n^2)`


### 插入排序

我们将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束

插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是 `O(1)`，也就是说，这是一个原地排序算法

在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序是稳定的排序算法

如果要排序的数据已经是有序的，我们并不需要搬移任何数据。如果我们从尾到头在有序数据组里面查找插入位置，每次只需要比较一个数据就能确定插入的位置。所以这种情况下，最好是时间复杂度为 `O(n)`

如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，所以最坏情况时间复杂度为 `O(n^2)`


### 选择排序

选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾

选择排序空间复杂度为 `O(1)`，是一种原地排序算法。选择排序的最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 `O(n^2)`

选择排序是一种不稳定的排序算法, 选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性

### 归并排序

归并排序的核心思想是很简单的。如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了

归并排序使用的就是**分治思想**。分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了


### 快速排序

如果要排序数组中下标从 `p` 到 `r` 之间的一组数据，我们选择 `p` 到 `r` 之间的任意一个数据作为 `pivot`（分区点）

我们遍历 `p` 到 `r` 之间的数据，将小于 `pivot` 的放到左边，将大于 `pivot` 的放到右边，将 `pivot` 放到中间。经过这一步骤之后，数组 `p` 到 `r` 之间的数据就被分成了三个部分，前面 `p` 到 `q-1` 之间都是小于 `pivot` 的，中间是 `pivot`，后面的 `q+1` 到 `r` 之间是大于 `pivot` 的

### 桶排序

核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了

#### 桶排序的使用条件

要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序

数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 `O(nlogn)` 的排序算法了


### 计数排序

当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间

数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数

#### 计数排序举例

50万考生，考生的满分是 900 分，最小是 0 分，这个数据的范围很小，所以我们可以分成 901 个桶，对应分数从 0 分到 900 分。根据考生的成绩，我们将这 50 万考生划分到这 901 个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。我们只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了 50 万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是 `O(n)`


### 基数排序

基数排序对要排序的数据是有要求的，需要可以分割出独立的**位**来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 `O(n)` 了

-------------------------------------------------

## 二分查找

二分查找算法，也叫折半查找算法, 是一种针对有序数据集合的查找算法

二分查找针对的是一个有序的数据集合，每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0

二分查找是一种非常高效的查找算法，我们假设数据大小是 n，每次查找后数据都会缩小为原来的一半，也就是会除以 2，时间复杂度就是 `O(logn)`

### 二分查找的实现

- 循环实现
- 递归实现

### 二分查找的局限性

二分查找的时间复杂度是 `O(logn)`，查找数据的效率非常高

- 二分查找依赖的是**数组**, 链表是不可以的，主要原因是二分查找算法需要按照下标随机访问元素
- 二分查找针对的是**有序数据**


## 跳表

**链表加多级索引的结构，就是跳表**

比起单纯的单链表，跳表需要存储多级索引，肯定要消耗更多的存储空间


## 散列表

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来

散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据

### 散列函数

列函数，我们可以把它定义成 `hash(key)`，其中 `key` 表示元素的键值，`hash(key)` 的值表示经过散列函数计算得到的散列值

### 散列冲突

再好的散列函数也无法避免散列冲突。那究竟该如何解决散列冲突问题呢？我们常用的散列冲突解决方法有两类

- 开放寻址法
- 链表法，在散列表中，每个桶会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中

### 散列函数的设计


--------------------------------------------

## 哈希算法

哈希算法的定义: 将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值

### 哈希算法的应用

- 安全加密
- 唯一标识
- 数据校验
- 散列函数

------------------------------------------

## 树

### 二叉树

二叉树每个节点最多有两个子节点，分别是左子节点和右子节点。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点


#### 满二叉树

叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫做满二叉树


#### 完全二叉树

叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树


### 二叉树的存储

- 基于指针的二叉链式存储法
- 基于数组的顺序存储法

#### 链式存储法

每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。我们只要拎住根节点，就可以通过左右子节点的指针，把整棵树都串起来。这种存储方式我们比较常用。大部分二叉树代码都是通过这种结构来实现的

#### 顺序存储法

基于数组的顺序存储法。我们把根节点存储在下标 `i = 1` 的位置，那左子节点存储在下标 `2 * i = 2` 的位置，右子节点存储在 `2 * i + 1 = 3` 的位置。以此类推，下一个节点的左子节点存储在 `2 * i = 2 * 2 = 4` 的位置，右子节点存储在 `2 * i + 1 = 2 * 2 + 1 = 5` 的位置

如果某棵二叉树是一棵完全二叉树，那用数组存储无疑是最节省内存的一种方式。因为数组的存储方式并不需要像链式存储法那样，要存储额外的左右子节点的指针

### 二叉树的遍历

- 前序遍历, 对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树
- 中序遍历, 对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树
- 后序遍历, 对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身

实际上，**二叉树的前、中、后序遍历就是一个递归的过程**。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树

#### 二叉树遍历的时间复杂度

每个节点最多会被访问两次，所以遍历操作的时间复杂度，跟节点的个数 n 成正比，也就是说二叉树遍历的时间复杂度是 `O(n)`


### 二叉查找树

二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树

**二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值**

在二叉查找树中查找一个节点: 我们先取根节点，如果它等于我们要查找的数据，那就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找

#### 二叉查找树的操作

- 查找
- 插入
- 删除

### B+ 树

-----------------------------------------

## 红黑树

### 平衡二叉树

二叉树中任意一个节点的左右子树的高度相差不能大于 1

平衡二叉查找树，其实就是让整棵树左右看起来比较对称、比较平衡，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些

**平衡二叉查找树的初衷，是为了解决二叉查找树因为动态更新导致的性能退化问题**

### 红黑树的定义

红黑树的英文是`Red-Black Tree`，简称 `R-B Tree`。它是一种不严格的平衡二叉查找树

红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求:

- 根节点是黑色的
- 每个叶子节点都是黑色的空节点，也就是说，叶子节点不存储数据
- 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的
- 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点


### 红黑树的实现


------------------------------------------

## 堆

- 堆是一个完全二叉树
- 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值


完全二叉树比较适合用数组来存储。用数组来存储完全二叉树是非常节省存储空间的。因为我们不需要存储左右子节点的指针，单纯地通过数组的下标，就可以找到一个节点的左右子节点和父节点

### 堆的操作

- 往堆中插入一个元素
- 删除堆顶元素

### 堆排序

- 建堆
- 排序

### 堆的应用

- 优先级队列
- 利用堆求 Top K


-----------------------------------

## 图

树中的元素我们称为节点，图中的元素我们就叫做顶点，图中的一个顶点可以与任意其他顶点建立连接关系。我们把这种建立的关系叫做边

- 有向图
- 无向图
- 带权图

### 图的存储

#### 邻接矩阵

邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 `i` 与顶点 `j` 之间有边，我们就将 `A[i][j]`和 `A[j][i]`标记为 `1`；对于有向图来说，如果顶点 `i` 到顶点 `j` 之间，有一条箭头从顶点 `i` 指向顶点 `j` 的边，那我们就将 `A[i][j]`标记为 `1`。同理，如果有一条箭头从顶点 `j` 指向顶点 `i` 的边，我们就将 `A[j][i]`标记为 `1`。对于带权图，数组中就存储相应的权重

#### 邻接表

每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点

时间、空间复杂度互换的设计思想: 邻接矩阵存储起来比较浪费空间，但是使用起来比较节省时间。相反，邻接表存储起来比较节省空间，但是使用起来就比较耗时间

-------------------------

## 搜索算法

深度优先搜索算法和广度优先搜索算法都是基于图这种数据结构的。这是因为，图这种数据结构的表达能力很强，大部分涉及搜索的场景都可以抽象成图

### 深度优先搜索

深度优先搜索，简称 DFS。最直观的例子就是走迷宫，假设你站在迷宫的某个岔路口，然后想找到出口。你随意选择一个岔路口来走，走着走着发现走不通的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。这种走法就是一种深度优先搜索策略

深度优先搜索用的是一种比较著名的算法思想，**回溯思想**。这种思想解决问题的过程，非常适合用**递归**来实现

### 广度优先搜索

广度优先搜索，我们平常都简称 BFS。直观地讲，它其实就是一种地毯式层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索

--------------------------------------

## 字符串匹配算法

### BF 算法

BF 算法中的 BF 是 Brute Force 的缩写，中文叫作暴力匹配算法，也叫朴素匹配算法。这种算法的字符串匹配方式很暴力，当然也就会比较简单、好懂，但相应的性能也不高

BF 算法的思想可以用一句话来概括，那就是，我们在主串中，检查起始位置分别是 `0、1、2…n-m` 且长度为 `m` 的 `n-m+1` 个子串，看有没有跟模式串匹配的

### RK 算法

RK 算法的全称叫 Rabin-Karp 算法，是由它的两位发明者 Rabin 和 Karp 的名字来命名的

RK 算法的思路是这样的：我们通过哈希算法对主串中的 `n-m+1` 个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。如果某个子串的哈希值与模式串相等，那就说明对应的子串和模式串匹配了

RK 算法是借助哈希算法对 BF 算法进行改造，即对每个子串分别求哈希值，然后拿子串的哈希值与模式串的哈希值比较，减少了比较的时间

### BM 算法

BM 算法核心思想是，利用模式串本身的特点，在模式串中某个字符与主串不能匹配的时候，将模式串往后多滑动几位，以此来减少不必要的字符比较，提高匹配的效率

### KMP 算法

KMP 算法的核心思想，跟 BM 算法非常相近。我们假设主串是 a，模式串是 b。在模式串与主串匹配的过程中，当遇到不可匹配的字符的时候，我们希望找到一些规律，可以将模式串往后多滑动几位，跳过那些肯定不会匹配的情况

------------------------------------------

## Trie 树

Trie 树，也叫字典树。顾名思义，它是一个树形结构。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题

Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起

### AC 自动机

经典的多模式串匹配算法

AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了

-----------------------------------------

## 基本的算法思想

- 贪心算法
- 分治算法
- 回溯算法
- 动态规划

