如果能够充分掌握算法的一些技巧，能够混合运用起来，那么写出来的代码，必然非常优雅

### 多思考能否使用位运算

如果你现在去找个 IDE 写个代码测试下 `n / 2` 和 `n >> 1` 的运行效率，可能会发现没啥差别，其实并非没有差别，而是大部分编译器会自动帮你把 `n / 2` 优化成 `n >> 1`

### 异或运算的妙用

关于异或的特性:

- 两个相同的数相互异或，运算结果为 0，例如 `n ^ n = 0`
- 任何数和 0 异或，运算结果不变，例如 `n ^ 0 = n`
- 支持交换律和结合律，例如 `x ^ ( y ^ x) = (x ^ y) ^ x`

### 考虑是否可以使用数组下标

数组的下标是一个隐含的很有用的数组，特别是在统计一些数字，或者判断一些整型数是否出现过的时候

### 考虑能否使用双指针

双指针这个技巧，就更加常用的，特别是在链表和有序数组中

- 快慢指针, 两个指针从同一侧开始遍历数组，将这两个指针分别定义为快指针和慢指针，两个指针以不同的策略移动，直到两个指针的值相等或其他特殊条件为止，如快指针每次增长两个，慢指针每次增长一个
- 对撞指针, 是指在有序数组中，将指向最左侧的索引定义为左指针，最右侧的定义为右指针，然后从两头向中间进行数组遍历
- 滑动窗口法, 两个指针，一前一后组成滑动窗口，并计算滑动窗口中的元素的问题


### 从递归到备忘录到递推或者动态规划

递归非常好用，好多问题都可以使用递归来解决，不过大部分的的递归问题都可以进行剪枝，并且还有很多带有备忘录的递归都可以转化为动态规划

遇到递归的问题，一定要考虑是否可以剪枝，是否可以把递归转化成递推

1. 对于可以递归的问题务必考虑是否有重复计算的
   当我们使用递归来解决一个问题的时候，容易产生重复去算同一个子问题，这个时候我们要考虑状态保存以防止重复计算
2. 考虑自底向上
   对于递归的问题，我们一般都是从上往下递归的，直到递归到最底，再一层一层着把值返回, 当n比较大的时候，例如当 `n = 10000`时，那么必须要往下递归10000层直到 `n <=2` 才将结果慢慢返回，如果n太大的话，可能栈空间会不够用, 对于这种情况，其实我们是可以考虑自底向上的做法的, 我们也把这种自底向上的做法称之为递推

使用递归解决问题的时候，要考虑以下两个问题

- 是否有状态重复计算的，可不可以使用备忘录法来优化
- 是否可以采取递推的方法来自底向上做，减少一味递归的开销


### 考虑是否可以设置哨兵位来处理临界问题

在链表的相关问题中，我们经常会设置一个头指针，而且这个头指针是不存任何有效数据的，只是为了操作方便，这个头指针我们就可以称之为哨兵位了


###  动态规划解题

动态规划算法是通过拆分问题，定义问题状态和状态之间的关系，使得问题能够以递推或者说分治的方式去解决

动态规划需要明确掌握几个重要概念：

- 阶段，对于一个完整的问题过程，适当的切分为若干个相互联系的子问题，每次在求解一个子问题，则对应一个阶段，整个问题的求解转化为按照阶段次序去求解
- 状态，状态表示每个阶段开始时所处的客观条件，即在求解子问题时的已知条件。状态描述了研究的问题过程中的状况
- 决策，决策表示当求解过程处于某一阶段的某一状态时，可以根据当前条件作出不同的选择，从而确定下一个阶段的状态，这种选择称为决策
- 策略，由所有阶段的决策组成的决策序列称为全过程策略，简称策略
- 最优策略，在所有的策略中，找到代价最小，性能最优的策略，此策略称为最优策略
- 状态转移方程，状态转移方程是确定两个相邻阶段状态的演变过程，描述了状态之间是如何演变的


### 巧用取余

有时候我们在遍历数组的时候，会进行越界判断，如果下标差不多要越界了，我们就把它置为0重新遍历。特别是在一些环形的数组中，例如用数组实现的队列。往往会写出这样的代码：

```
for i := 0; i < n; i++ {
       if (pos < n) {
        //没有越界
        // 使用数组arr[pos]
        else {
          pos = 0 //置为0再使用数组
          //使用arr[pos]
         }
        pos++
   }

```

实际上我们可以通过取余的方法来简化代码

```
for i := 0; i < n; i++ {
  //使用数组arr[pos]   (我们假设刚开始的时候pos < N)
  pos = (pos + 1) % n;
}
```

### 字典表的运用

待补充

### 巧用移位运算

有时候我们在进行除数或乘数运算的时候，例如`n/2`，`n/4`, `n/8`这些运算的时候，我们就可以用移位的方法来运算了，这样会快很多

```
n/2 等价于 n>>1

n/4 等价于 n>>2

n/8 等价于 n>>3
```

### 递归优化问题

#### 对于可以递归的问题考虑状态保存

当我们使用递归来解决一个问题的时候，容易产生重复去算同一个子问题，这个时候我们要考虑状态保存以防止重复计算

*问题：* 一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法？

这个问题用递归很好解决。假设 `f(n)` 表示n级台阶的总跳数法，则有 `f(n) = f(n-1) + f(n - 2)`, 递归的结束条件是当`0 <= n <= 2`时, f(n) = n。因此我们可以很容易写出递归的代码

不过对于可以使用递归解决的问题，我们一定要考虑是否有很多重复计算。显然对于 `f(n) = f(n-1) + f(n-2)` 的递归，是有很多重复计算的

这个时候我们要考虑状态保存。例如用 Map 来进行保存，当然用一个数组也是可以的，这个时候就像我们上面说的巧用数组下标了。可以当`arr[n] = 0`时，表示n还没计算过，当`arr[n] != 0`时，表示`f(n)`已经计算过，这时就可以把计算过的值直接返回回去了

这样，可以极大着提高算法的效率。也有人把这种状态保存称之为**备忘录法**

#### 考虑自底向上

对于递归的问题，我们一般都是从上往下递归的，直到递归到最底，再一层一层着把值返回

不过，有时候当n比较大的时候，例如当 n = 10000时，那么必须要往下递归10000层直到 n <=2 才将结果慢慢返回，如果n太大的话，可能栈空间会不够用

对于这种情况，其实我们是可以考虑自底向上的做法的。例如我知道 `f(1) = 1;`, `f(2) = 2;`. 那么我们就可以推出 `f(3) = f(2) + f(1) = 3`。从而可以推出`f(4)`, `f(5)`等直到`f(n)`。因此，我们可以考虑使用自底向上的方法来做, 我们也把这种自底向上的做法称之为**递推**


-----------------------------------------------------

## 常见算法技巧

### 1. 确定函数名字与原型

一旦拿到有关算法的问题，那么就应该分析问题，找到对应的输入输出，从而确定出算法的函数原型。我们写算法，其实就是写一个或者若干个普通的函数。因此，需要分析出，应该传什么参数给函数，函数处理完后，应该把什么数据作为结果返回。最后还要给函数取一个符合算法意义的名字，名字最好用英语表示，如果用拼音，会显得特别山寨的感觉。函数的命名方式与变量的命名方式都有相关的约定，比如匈牙利命名法，Linux命名法或者驼峰命名法等

此外，就是需要有模块化的思想。一个函数只单独完成一个单一的功能，函数的代码行数一般很少超过100行，加上注释不会超过300行。 因此，要把那些频繁使用而功能又比较单一的代码放在一个独立的函数里。不要在一个函数里完成N个功能，这不利于调试和维护，也和模块化是相背离的

### 2. 严进宽出

确定好了函数的原型之后，紧接着在完成这个函数的功能一开始的地方，就需要严格判断函数输入参数的合法性，我们称之为：严进宽出。具体点说，就是要判断:
- 函数参数中的指针是否为NULL
- 函数参数中缓存的长度是否在合理范围
- 对参数类型进行检查

严进宽出是写程序的一个非常好的习惯，可以避免程序在运行中出错，甚至避免各种严重漏洞的产生。比如曾经十分严重的SSL协议中的心脏流血漏洞，就是因为服务端程序在处理的时候，没有验证来自客户端对应的缓存长度的有效性，而造成了该漏洞的产生。同样，对于号称漏洞核弹的微软CVE-2017-0290漏洞，也是因为在扫描引擎MsMpEng的NScript模块中没有对输入的参数类型进行检查就默认当做字符串来处理造成的

此外，在函数内部定义的局部变量，都应该进行初始化，因为未初始化的变量，包含的都是一些没有意义的随机值，初始化可以防止在使用过程中使用了垃圾值的变量，影响程序的判断，尤其是指针，可以防止野指针破坏程序中的数据

### 3. 边界考虑

边界考虑就是要考虑程序中各种各样的特殊情况，而不是只考虑其中的一种情况。我们在写算法的时候，经常会忘记多种情况的周全考虑，而忽略了很多特殊的情况，对程序的健壮性带来影响

### 4. 出错处理

出错处理，是指当代码在执行过程中，如果发生了异常或者错误，就必须要处理，否则程序就无法继续执行了，如果强制继续执行，往往可能会导致程序或者系统崩溃

### 5. 性能优化（时间复杂度，空间复杂度）

总的来说，衡量算法的优劣有2种标准：时间复杂度和空间复杂度。简单的来说，所谓时间复杂度，就是嵌套的循环越少越好，比如一层循环优于二层循环，面试中一般很少有三层循环的算法；而所谓空间复杂度，就是尽量不要调用malloc或者new来分配额外的内存。复杂度可以用O（）来表示，它们之间的效率关系为：`O(1)>O(logn)>O(n)>O(nlogn)>O(n²)>O(2^n)`

### 6. 循环的掌握

一个再复杂的算法程序，都是由**循环，条件，顺序**三种语句构成的。而这三种语句中，**循环语句**的使用是其中的关键。循环语句用来遍历和操作对应的数据结构，在遍历的过程中，完成对数据的处理和问题的解决。以循环语句为核心，循环语句把其他语句联系起来。因此，算法中，最重要的地方就是对循环的熟练掌握与使用

熟练各种循环语句的写法，为实现各种复杂的算法奠定了基础。因此，要在各种循环语句上下功夫，达到熟练书写，灵活运用的程度

### 7. 递归的应用

对于一些复杂的算法问题，还可以通过递归的思想来解决。有的问题，用传统的方法来解决，显得很复杂。这个时候，可以考虑是不是可以用递归来解决。因为用递归的思想解决问题，既简单，又清晰，往往让看似复杂的问题得到简单解决的可能

对于**树的问题**，几乎都可以考虑用递归的方法去实现，按照递归的方法，首先分析了这个问题最简单的情况（即递归的终止条件），然后再对复杂的情况利用递归方法调用它自身

**递归算法的关键是找到递归的终止条件和递归公式**

### 8. 2个指针跑步

2个指针跑步法，是麦洛克菲在算法教学过程中总结的一个很好的编程方法。就是在算法实现过程中，我们可以定义2个（有时候甚至是3个或者多个）指针，一前一后同向或者相向而行，同时遍历对应的数据结构（如数组，链表，字符串等），在遍历过程中解决对应的问题。如果我们把循环比喻成算法问题中的导演，那么2个指针就是算法中的男女主角，对问题的解决起着重要的作用。在大量的名企面试题中，都可以使用该方法来解决并降低算法的复杂度

### 9. Hash算法

善用map 类型


--------------------------------------------------

### 算法思路指南

#### 数据结构的存储方式

数据结构的存储方式只有两种：
- 数组，链式存储
- 链表，链式存储

散列表、栈、队列、堆、树、图等等各种数据结构都属于「上层建筑」，数组和链表才是「结构基础」，这些多样化的数据结构，究其源头，都是在链表或者数组上的特殊操作

比如说「队列」、「栈」这两种数据结构既可以使用链表也可以使用数组实现。用数组实现，就要处理扩容缩容的问题；用链表实现，没有这个问题，但需要更多的内存空间存储节点指针

「图」的两种表示方法，邻接表就是链表，邻接矩阵就是二维数组。邻接矩阵判断连通性迅速，并可以进行矩阵运算解决一些问题，但是如果图比较稀疏的话很耗费空间。邻接表比较节省空间，但是很多操作的效率上肯定比不过邻接矩阵

「散列表」就是通过散列函数把键映射到一个大数组里。而且对于解决散列冲突的方法，拉链法需要链表特性，操作简单，但需要额外的空间存储指针；线性探查法就需要数组特性，以便连续寻址，不需要指针的存储空间，但操作稍微复杂些

「树」，用数组实现就是「堆」，因为「堆」是一个完全二叉树，用数组存储不需要节点指针，操作也比较简单；用链表实现就是很常见的那种「树」，因为不一定是完全二叉树，所以不适合用数组存储。为此，在这种链表「树」结构之上，又衍生出各种巧妙的设计，比如二叉搜索树、AVL 树、红黑树、区间树、B 树等等，以应对不同的问题


- 数组由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间。但正因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)；而且你如果想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N)
- 链表因为元素不连续，而是靠指针指向下一个元素的位置，所以不存在数组的扩容问题；如果知道某一元素的前驱和后驱，操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)。但是正因为存储空间不连续，你无法根据一个索引算出对应元素的地址，所以不能随机访问；而且由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间

#### 数据结构的基本操作

**对于任何数据结构，其基本操作无非`遍历 + 访问`，再具体一点就是：`增删查改`**

数据结构种类很多，但它们存在的目的都是在不同的应用场景，尽可能高效地增删查改, 这就是数据结构的使命

各种数据结构的遍历 + 访问无非两种形式：
- 线性
- 非线性

**线性就是 `for/while` 迭代为代表，非线性就是递归为代表**


数组遍历框架，典型的线性迭代结构:
```
func traverse(arr []int) {
   for i := 0; i < len(arr); i++ {
      //迭代访问arr[i]
   }
}
```

链表遍历框架，兼具迭代和递归结构:
```
type ListNode struct {
   Val int
   Next *LIstNode
}

//迭代访问
func traverse(head *ListNode) {
   for head != nil {
      //迭代访问 head.Val
      head = head.Next
   }
}

//递归访问
func traverse(head *ListNode) {
   //递归访问 head.Val
   traverse(head.Next)
}
```

二叉树遍历框架，典型的非线性递归遍历结构:
```
type TreeNode struct {
   Val int
   Left *ListNode
   Right *ListNode
}

func traverse(root *TreeNode) {
   fmt.Println(root.Val)
   traverse(root.Left)
   traverse(root.Right)
}
```

**所谓框架，就是套路。不管增删查改，这些代码都是永远无法脱离的结构，你可以把这个结构作为大纲，根据具体问题在框架上添加代码就行了**

#### 算法刷题指南

首先要明确的是，数据结构是工具，算法是通过合适的工具解决特定问题的方法。也就是说，学习算法之前，最起码得了解那些常用的数据结构，了解它们的特性和缺陷

先刷二叉树题目，因为二叉树是最容易培养框架思维的，而且大部分算法技巧，本质上都是树的遍历问题，几乎所有二叉树的题目都是一套这个框架就出来了：
```
func traverse(root *ListNode) {
   //前序遍历
   traverse(root.Left)
   //中序遍历
   traverse(root.Right)
   //后序遍历
}
```

常见问题：
- 求二叉树中最大路径和
- 根据前序遍历和中序遍历的结果还原一棵二叉树


**在回溯，分治，动态规划问题中，涉及到递归问题的，大部分都是树的问题**

很多动态规划问题就是在遍历一棵树，如果对树的遍历操作烂熟于心，知道怎么把思路转化成代码，知道如何提取别人解法的核心思路，就ok了

*数据结构的基本存储方式就是链式和顺序两种，基本操作就是增删查改，遍历方式无非迭代和递归*


-------------------------------------------

### 递归理解

**尾递归**: 如果一个函数中所有递归形式的调用都出现在函数的末尾，我们称这个递归函数是尾递归的。 当递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分时，这个递归调用就是尾递归。 尾递归函数的特点是在回归过程中不用做任何操作，这个特性很重要，因为大多数现代的编译器会利用这种特点自动生成优化的代码

尾递归特征:
- 在尾部调用的是函数自身
- 可通过优化，使得计算仅占用常量栈空间

```
func recsum(x int) int {
   if x == 1 {
      return x
   } else {
      return x + recsum(x-1)
   }
}
```

递归三要素：
- 确定递归函数功能
- 找出递归结束的条件
- 找出函数的等价关系式

递归函数往往可以简化我们的代码，尤其是对树的遍历和利用回溯算法写代码的时候，但是**递归函数的返回值**往往是困扰我们的。

总体来说，我们先要理解函数的调用过程，函数调用过程会用栈来保存函数的返回值和过程，而递归函数就是调用自身函数的过程，所以也是用栈存储，这样就比较容易理解了

递归函数是用栈存储函数返回值和中间过程，每次返回栈顶的结果（包括中间的输出值和返回值），而**递归函数最终的返回值的是栈底的值，也就是递归函数第一次调用时的返回值**


写递归算法的关键是要明确函数的「定义」是什么，然后相信这个定义，利用这个定义推导最终结果，绝不要跳入递归的细节

---------------------------------------------------------

### 动态规划

动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解

动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解

与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算，节省时间。我们可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。具体的动态规划算法多种多样，但它们具有相同的填表格式

#### 多阶段决策问题

如果一类活动过程可以分为若干个互相联系的阶段，在每一个阶段都需作出决策，一个阶段的决策确定以后，常常影响到下一个阶段的决策，从而就完全确定了一个过程的活动路线，则称它为多阶段决策问题

各个阶段的决策构成一个决策序列，称为一个策略。每一个阶段都有若干个决策可供选择，因而就有许多策略供我们选取，对应于一个策略可以确定活动的效果，这个效果可以用数量来确定。策略不同，效果也不同，多阶段决策问题，就是要在可以选择的那些策略中间，选取一个最优策略，使在预定的标准下达到最好的效果

- 阶段: 把所给求解问题的过程恰当地分成若干个相互联系的阶段，以便于求解，过程不同，阶段数就可能不同．描述阶段的变量称为阶段变量
- 状态: 状态表示每个阶段开始面临的自然状况或客观条件，它不以人们的主观意志为转移，也称为不可控因素。状态就是某阶段的出发位置，它既是该阶段某路的起点，同时又是前一阶段某支路的终点
- 无后效性: 我们要求状态具有下面的性质：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响，所有各阶段都确定时，整个过程也就确定了
- 决策: 一个阶段的状态给定以后，从该状态演变到下一阶段某个状态的一种选择称为决策。在最优控制中，也称为控制。在许多问题中，决策可以自然而然地表示为一个数或一组数。不同的决策对应着不同的数值。描述决策的变量称决策变量，因状态满足无后效性，故在每个阶段选择决策时只需考虑当前的状态而无须考虑过程的历史
- 由每个阶段的决策组成的序列称为策略


**多阶段决策问题中，各个阶段采取的决策，一般来说是与时间有关的，决策依赖于当前状态，又随即引起状态的转移，一个决策序列就是在变化的状态中产生出来的，故有`动态`的含义，称这种解决多阶段决策最优化问题的方法为动态规划方法**

#### 动态规划适用条件

任何思想方法都有一定的局限性，超出了特定条件，它就失去了作用。同样，动态规划也并不是万能的。适用动态规划的问题必须满足**最优化原理**和**无后效性**

- 最优子结构性质: 一个最优化策略的子策略总是最优的
- 无后效性: 将各阶段按照一定的次序排列好之后，对于某个给定的阶段状态，它以前各阶段的状态无法直接影响它未来的决策，而只能通过当前的这个状态。换句话说，每个状态都是过去历史的一个完整总结。这就是无后向性，又称为无后效性
- 子问题的重叠性: **动态规划算法的关键在于解决冗余，这是动态规划算法的根本目的**。动态规划实质上是一种以空间换时间的技术，它在实现的过程中，不得不存储产生过程中的各种状态，所以它的空间复杂度要大于其他的算法。选择动态规划算法是因为动态规划算法在空间上可以承受，而搜索算法在时间上却无法承受，所以我们舍空间而取时间


**动态规划对于解决多阶段决策问题的效果是明显的，但是动态规划也有一定的局限性。首先，它没有统一的处理方法，必须根据问题的各种性质并结合一定的技巧来处理**


----------------------------------------

### 常用位运算操作

1. 利用 或操作 `|` 和 空格 将英文字符转换为小写

```
('a' | ' ') == 'a'
('A' | ' ') == 'a'
```

2. 利用 与操作 `&` 和 下划线 将英文字符转换为大写

```
('b' & '_') == 'B'
('B' & '_') == 'B'
```

3. 利用异或操作 `^` 和 空格 进行英文字符大小写互换

```
('d' ^ ' ') == 'D'
('D' ^ ' ') == 'd'
```

以上操作能够产生奇特效果的原因在于 `ASCII` 编码。字符其实就是数字，恰巧这些字符对应的数字通过位运算就能得到正确的结果，有兴趣的读者可以查 `ASCII` 码表自己算算

4. 判断两个数是否异号

```
var x, y int = -1, 2
f := (x^y) < 0 //true

var x, y int = 3, 2
f := (x^y) < 0 //false
```

这个技巧还是很实用的，利用的是补码编码的符号位。如果不用位运算来判断是否异号，需要使用 if else 分支，还挺麻烦的。利用乘积或者商来判断两个数是否异号，但是这种处理方式可能造成溢出，从而出现错误

5. 不用临时变量交换两个数

```
var a, b int = 1, 2
a ^= b
b ^= a
a ^= b
```

6. 加一

```
var n int = 1
n = -^n  //现在 n = 2
```

7. 减一

```
var n int = 2
n = ^-n  //现在 n = 1
```

### 算法常用位运算操作

`n&(n-1)` 这个操作是算法中常见的，作用是消除数字 n 的二进制表示中的最后一个 1

```
n:       110100
n-1:     110011
n&(n-1): 110000
```
**核心逻辑就是，`n - 1` 一定可以消除最后一个 1，同时把其后的 0 都变成 1，这样再和 n 做一次 `&` 运算，就可以仅仅把最后一个 1 变成 0 了**

1. 返回 n 的二进制表示中有几个 1

因为 `n & (n - 1)` 可以消除最后一个 1，所以可以用一个循环不停地消除 1 同时计数，直到 n 变成 0 为止
```
func hammingWeifht(n int) int {
   res := 0
   for n != 0 {
      n = n&(n-1)
      res++
   }
   return res
}
```

2. 判断一个数是不是 2 的指数

一个数如果是 2 的指数，那么它的二进制表示一定只含有一个 1

如果使用 `n&(n-1)` 的技巧就很简单了
```
func isPowOfTwo(n int) bool {
   if n <= 0 {
      return false
   }
   return (n&(n-1)) == 0
}
```

3. 查找只出现一次的元素

一个数和它本身做异或运算结果为 0，即 `a ^ a = 0`；一个数和 0 做异或运算的结果为它本身，即 `a ^ 0 = a`

```
func singleNumber(nums []int) int {
   res := 0
   for _, v := range nums {
      res ^= v
   }
   return res
}
```

-----------------------------------------

### 滑动窗口算法

这个算法技巧的思路非常简单，就是维护一个窗口，不断滑动，然后更新答案

```
var left, right := 0, 0
for right < len(window) {
   //增大窗口
   window.append(window, window[right])
   right++

   for 需要缩小窗口 {
      //缩小窗口
      window = window[left+1:]
      left++
   }
}
```

其实困扰大家的，不是算法的思路，而是各种细节问题。比如说如何向窗口中添加新元素，如何缩小窗口，在窗口滑动的哪个阶段更新结果

----------------------------------------------------------

### 二叉树解题技巧

**为递归而生---树**

递归的两个重要环节:
- 反复调用自身
- 终止条件

#### 树的基本操作

- 求树的深度
- 求叶子结点的个数
- 对树进行遍历(前，中，后序遍历)


求树的深度:
```
func getTreeHigh(root *TreeNode) int {
   if root == nil {
      return 0
   }
   left := getTreeHigh(root.Left)
   right := getTreeHigh(root.Right)
   return int(math.Max(int64(left), int64(right))) + 1
}
```

计算叶子结点个数:
```
var num int
func leafpointNum(root *TreeNode) {
   if root == nil {
      return 0
   }
   //左右结点为空的即为叶子结点
   if root.Left == nil && root.Right == nil {
      num++
   }

   leafpointNum(root.Left)
   leafpointNum(root.Right)
}
```

#### 二叉树树的各种遍历

- 前序遍历
- 中序遍历
- 后序遍历

在遍历时，如果是递归，就方便很多，但是迭代就会有难度，因为递归最终会回到根结点，完成左子树后继续右子树，但是迭代可就没有这种优势了，和单向链表一样，都是单程路线，此时，就需要在单程路线中记录下需要需要回头才能处理的点


#### N叉树的遍历

- 深度优先搜索, DFS, 即递归
- 广度优先搜索, BFS, 即迭代, 借助队列


#### 二叉搜索树

**二叉搜索树，最大的特点就是比根小的放在左孩子结点，比根大的放在右孩子结点，二叉搜索树的中序遍历，是一个有序数组**, 这是二叉搜索树的重要特点，也是解题关键

- 二叉搜索树的中序遍历的序列是递增排序的序列
- 在二叉搜索树中的插入、删除、搜索的复杂度等于树高，即`log(n)`
- 在二叉搜索树中找最小节点和最大节点也很方面，如要找最小节点，只需从根节点开始，一直找左子树，当某个节点没有左子树时，该节点就是最小节点，即终止节点就是最小节点。同理，如果要找最大节点，那么从根节点开始一直找右子树即可，当某个节点没有右子树时，该节点就是最大节点


[二叉树解题技巧三](https://cloud.tencent.com/developer/article/1756156)


二叉树的问题，多半是需要你遍历这个树，只不过是在遍历的过程中，不同的题目要求你做的计算不一样, 这里有两个遍历方法，递归和非递归

**递归的解法是利用了系统中提供的函数栈，非递归我们需要手动创建这么一个数据结构**


-----------------------------------------------------------

### 链表解题技巧

- 数组在物理内存上必须是连续的
- 链表在物理内存上不需要连续，通过指针连接

其实链表相关的题目没有很难的，套路也就这么几个，其中最常考最基础的题目是**反转链表**



链表在新增、删除数据都比较容易，可以在 `O(1)` 的时间复杂度内完成。但对于查找，不管是按照位置的查找还是按照数值条件的查找，都需要对全部数据进行遍历。这显然就是 `O(n)` 的时间复杂度

虽然链表在新增和删除数据上有优势，但仔细思考就会发现，这个优势并不实用。这主要是因为，在新增数据时，通常会伴随一个查找的动作

线性表真正的价值在于，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针。如果数据的元素个数不确定，且需要经常进行数据的新增和删除时，那么链表会比较合适。如果数据元素大小确定，删除插入的操作并不多，那么数组可能更适合些

- 链表翻转（三个指针）
- 快慢指针（两个指针）

链表的基本操作:
|操作|时间复杂度|
|---|---|
|查找|O(n)|
|插入|O(1), 仅插入本身,加上查找就是O(n)|
|删除|O(1), 仅删除本身,加上查找就是O(n)|

链表类型:
|链表类型|定义|
|---|---|
|单链表|节点只有一个指针，指向后继节点|
|双链表|节点有两个指针，一个指向前置节点，一个指向后继节点|
|循环链表|链表首尾相连|

#### 链表解题原则

- 画图, 表的题目很容易把人绕晕，通过画图能够很思路理清，不容易弄错. 画图时要聚焦子结构，忽略其他信息
- 主要考点: 指针的修改, 链表的拼接
- 虚拟头: 用一个虚拟头指向头节点，虚拟头就是新的头节点了，而虚拟头不是题目给的节点，不参与运算，因此不需要特殊判断
- 快慢指针: 搞两个指针，一个大步走, 一次走两步. 一个小步走, 一次走一步

#### 链表注意事项

- 出现了环，造成死循环
- 分不清边界，导致边界条件出错
- 搞不懂递归怎么做


[链表解题技巧一](https://www.cxyxiaowu.com/7913.html)

[链表解题技巧二](https://tsejx.github.io/data-structure-and-algorithms-guidebook/algorithms/summary/linked-list#%E5%8F%8C%E6%8C%87%E9%92%88%E6%B3%95)

[链表解题技巧三](https://blog.csdn.net/zqxnum1/article/details/48156913)

[链表解题技巧四](https://www.cnblogs.com/waring/p/4538042.html)

[链表解题技巧五](https://lucifer.ren/leetcode/thinkings/linked-list.html)


#### 缓存

使用`数组或者 map` 来缓存链表中结点的信息, 具体实现思路是先使用一个数组或者 map 来存储链表中的结点信息，比如结点的数据值等，之后根据题目要求对数组进行相关操作后，再重新把数组元素做为每一个结点连接成链表返回即可。虽然使用缓存来解链表题有违链表题的本意，而且空间复杂度也达到了 `O(n)`, 但这种方法的确很简单易懂，看完题目后几乎就可以马上动手不加思考地敲代码一次 AC 了，不像常规操作那样需要去考虑到很多边界情况和结点指向问题

使用常规方法的话，你还可以分别使用**迭代和递归**来解题，迭代写起来比较容易，而递归的难点在于把握递归边界和递归式，但只要理解清楚了的话，递归的代码写起来真的很少

#### 快慢指针

最基本的链表循环过程:
```
cur := head
for cur != nil {
   cur = cur.Next
}
```

快慢指针其实是利用两个变量同时循环链表，区别在于一个的速度快一个的速度慢。比如慢指针slow的速度是 1，每趟循环都指向当前结点的下一个结点，即`slow = slow.next`。而快指针fast的速度可以是 2，每趟循环都指向当前结点的下下个结点，即`fast = fast.next.next`, 使用的时候需要特别注意`fast.next`是否为null，否则很可能会报错

两个速度不相同的人在同一个环形操场跑步，那么这两个人最后是不是一定会相遇。同样的道理，一个环形链表，快慢指针同时在里面移动，那么它们最后也一定会在链表的环中相遇。所以只要在循环链表的过程中，快慢指针相等了就代表该链表中有环


#### 先后指针

先后指针和快慢指针很类似，不同的是先后指针的移动速度是一样的，而且两者并没有同时开始移动，是一前一后从头节点出发的。先后指针主要用来寻找链表中倒数第 k 个结点。通常我们寻找链表中倒数第 k 个结点可以有两种办法:
- 先循环一遍链表计算它的长度n，再正向循环一遍找到该结点的位置
- 使用双向链表，先移动到链表结尾处再开始回溯 k 步, 但大多时候给的链表都是单向链表，这就又需要我们先循环一遍链表给每一个结点增加一个前驱了

使用先后指针的话只需要一趟循环链表，实现思路是先让快指针走 `k-1` 步，再让慢指针从头节点开始走，这样当快指针走到最后一个结点的时候，慢指针就走到了倒数第 k 个结点

#### 双向链表

双向链表是在普通的链表上给每一个结点增加pre属性来指向它的上一个结点，这样就可以通过某一个结点直接找到它的前驱而不需要专门去缓存了

#### 递归

使用递归解决链表问题不得不说是十分契合的，因为很多链表问题都可以分割成几个相同的子问题以缩小问题规模，再通过调用自身返回局部问题的答案从而来解决大问题的


----------------------------------------------------------------


### 重要--递归思想

「递归」，先有「递」再有「归」，「递」的意思是将问题拆解成子问题来解决， 子问题再拆解成子子问题，直到被拆解的子问题无需再拆分成更细的子问题，即可以求解，「归」是说最小的子问题解决了，那么它的上一层子问题也就解决了，上一层的子问题解决了，上上层子问题自然也就解决了, 直到最开始的问题解决

- 一个问题可以分解成具有相同解决思路的子问题，子子问题，换句话说这些问题都能调用同一个函数
- 经过层层分解的子问题最后一定是有一个不能再分解的固定值的，即终止条件,如果没有的话,就无穷无尽地分解子问题了，问题显然是无解的

递归解题的基本套路:
- 先定义一个函数，明确这个函数的功能，由于递归的特点是问题和子问题都会调用函数自身，所以这个函数的功能一旦确定了， 之后只要找寻问题与子问题的递归关系即可
- 接下来寻找问题与子问题间的关系, 即递推公式，这样由于问题与子问题具有相同解决思路，只要子问题调用步骤 1 定义好的函数，问题即可解决。所谓的关系最好能用一个公式表示出来，比如 `f(n) = n*f(n-1`) 这样
- 将第二步的递推公式用代码表示出来补充到步骤 1 定义的函数中
- 最后也是很关键的一步，根据问题与子问题的关系，推导出时间复杂度,如果发现递归时间复杂度不可接受，则需转换思路对其进行改造，看下是否有更靠谱的解法

------------------------------------------------------------


### 8种常用算法思想

- 枚举
- 递推
- 递归
- 分治
- 贪心
- 试探法
- 动态迭代
- 模拟

#### 枚举算法思想

枚举算法思想的最大特点是，在面对任何问题时它会去尝试每一种解决方法。在进行归纳推理时，逐个考察了某类事件的所有可能情况，因而得出一般结论，那么这个结论是可靠的，这种归纳方法叫作枚举法

**枚举算法的思想是**：将问题的所有可能的答案一一列举，然后根据条件判断此答案是否合适，保留合适的，丢弃不合适的。在C语言中，枚举算法一般使用`while`循环实现。使用枚举算法解题的基本思路如下:
- 确定枚举对象、枚举范围和判定条件
- 逐一列举可能的解，验证每个解是否是问题的解

#### 递推算法思想

递推算法能够通过已知的某个条件，利用特定的关系得出中间推论，然后逐步递推，直到得到结果为止。由此可见，递推算法要比枚举算法聪明，它不会尝试每种可能的方案

递推算法可以不断利用已有的信息推导出新的东西，在日常应用中有如下两种递推 算法:
- 顺推法：从已知条件出发，逐步推算出要解决问题的方法。例如斐波那契数列就可以通过顺推法不断递推算出新的数据
- 逆推法：从已知的结果出发，用迭代表达式逐步推算出问题开始的条件，即顺推法的逆过程

#### 递归算法思想

在计算机编程应用中，递归算法对解决大多数问题是十分有效的，它能够使算法的描述变得简洁而且易于理解

递归算法实际上是把问题转化为规模缩小了的同类问题的子问题，然后再递归调用函数或过程来表示问题的解

- 递归是在过程或函数中调用自身的过程
- 在使用递归策略时，必须有一个明确的递归结束条件，这称为递归出口
- 递归算法通常显得很简洁，但是运行效率较低，所以一般不提倡用递归算法设计程序
- 在递归调用过程中，系统用栈来存储每一层的返回点和局部量。如果递归次数过多，则容易造成栈溢出，所以一般不提倡用递归算法设计程序

#### 分治算法思想

分治算法也采取了各个击破的方法，将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。只要求出子问题的解，就可得到原问题的解

在编程过程中，经常遇到处理数据相当多、求解过程比较复杂、直接求解法会比较耗时的问题。在求解这类问题时，可以采用各个击破的方法

**具体做法是**：先把这个问题分解成几个较小的子问题，找到求出这几个子问题的解法后，再找到合适的方法，把它们组合成求整个大问题的解。如果这些子问题还是比较大，还可以继续再把它们分成几个更小的子问题，以此类推，直至可以直接求出解为止。这就是分治算法的基本思想

使用分治算法解题的一般步骤如下:
- 分解，将要解决的问题划分成若干个规模较小的同类问题
- 求解，当子问题划分得足够小时，用较简单的方法解决
- 合并，按原问题的要求，将子问题的解逐层合并构成原问题的解

#### 贪心算法思想

贪心算法也被称为贪婪算法，它在求解问题时总想用在当前看来是最好方法来实现。这种算法思想不从整体最优上考虑问题，仅仅是在某种意义上的局部最优求解

贪心算法从问题的某一个初始解出发，逐步逼近给定的目标，以便尽快求出更好的解。当达到算法中的某一步不能再继续前进时，就停止算法，给出一个近似解。由贪心算法的特点和思路可看出，贪心算法存在以下3个问题:
- 不能保证最后的解是最优的
- 不能用来求最大或最小解问题
- 只能求满足某些约束条件的可行解的范围

#### 试探算法思想

试探法也叫回溯法，试探法的处事方式比较委婉，它先暂时放弃关于问题规模大小的限制，并将问题的候选解按某种顺序逐一进行枚举和检验。当发现当前候选解不可能是正确的解时，就选择下一个候选解

